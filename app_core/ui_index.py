# -*- coding: utf-8 -*-
"""ç´¢å¼•ç®¡ç†ç›¸å…³çš„ Streamlit UI ç»„ä»¶ã€‚"""

import json
import os
from datetime import datetime

import streamlit as st
import pandas as pd

from app_core.semantic_index import (
    _load_index,
    _load_index_domain,
    build_project_vector_index,
    build_strategy_index_for_domain,
    rebuild_project_semantic_index,
)
from app_core.config import SEM_INDEX_ROOT
from app_core.text_utils import _split_pair_for_index


def _collect_index_overview():
    """æ‰«æè¯­ä¹‰ç´¢å¼•æ ¹ç›®å½•ï¼Œç”ŸæˆæŒ‰â€œé¢†åŸŸ/ç±»å‹â€åˆ†ç±»çš„ç´¢å¼•åˆ—è¡¨ã€‚"""

    overview = []
    if not os.path.exists(SEM_INDEX_ROOT):
        return overview

    for domain in sorted(os.listdir(SEM_INDEX_ROOT)):
        domain_dir = os.path.join(SEM_INDEX_ROOT, domain)
        if not os.path.isdir(domain_dir):
            continue

        for kb_type in sorted(os.listdir(domain_dir)):
            type_dir = os.path.join(domain_dir, kb_type)
            if not os.path.isdir(type_dir):
                continue

            idx_path = os.path.join(type_dir, "index.faiss")
            vec_path = os.path.join(type_dir, "vectors.npy")
            map_path = os.path.join(type_dir, "mapping.json")

            entry_cnt = 0
            try:
                if os.path.exists(map_path):
                    with open(map_path, "r", encoding="utf-8") as f:
                        mapping = json.load(f)
                        if isinstance(mapping, list):
                            entry_cnt = len(mapping)
            except Exception:
                entry_cnt = 0

            mode = "æœªç”Ÿæˆ"
            size_bytes = 0
            mtimes = []
            for pth, label in [(idx_path, "faiss"), (vec_path, "npy"), (map_path, "mapping")]:
                if os.path.exists(pth):
                    mtimes.append(os.path.getmtime(pth))
                    size_bytes += os.path.getsize(pth)
                    if mode == "æœªç”Ÿæˆ":
                        mode = label

            overview.append(
                {
                    "é¢†åŸŸ": domain,
                    "ç±»å‹": kb_type,
                    "æ¡ç›®æ•°": entry_cnt,
                    "æ–‡ä»¶çŠ¶æ€": mode,
                    "åˆè®¡å¤§å°(MB)": round(size_bytes / 1024 / 1024, 2) if size_bytes else 0,
                    "æœ€è¿‘æ›´æ–°æ—¶é—´": datetime.fromtimestamp(max(mtimes)).strftime("%Y-%m-%d %H:%M")
                    if mtimes
                    else "-",
                    "å­˜å‚¨ç›®å½•": os.path.relpath(type_dir, start=os.path.dirname(SEM_INDEX_ROOT)),
                }
            )

    return overview


def render_index_overview(st):
    """å¯è§†åŒ–å±•ç¤ºå·²æœ‰ç´¢å¼•åˆ—è¡¨ï¼Œæ–¹ä¾¿æŸ¥çœ‹ç´¢å¼•ç§ç±»ä¸åˆ†ç±»ã€‚"""

    st.markdown("### ğŸ—‚ï¸ ç´¢å¼•æ€»è§ˆï¼ˆæŒ‰é¢†åŸŸ/ç±»å‹åˆ†ç±»ï¼‰")
    overview = _collect_index_overview()
    if not overview:
        st.info("å½“å‰æ²¡æœ‰ç”Ÿæˆä»»ä½•ç´¢å¼•ã€‚è¯·å…ˆåœ¨é¡¹ç›®æˆ–é¢†åŸŸé¡µä¸­æ„å»ºç´¢å¼•ã€‚")
        return

    df = pd.DataFrame(overview)

    type_options = sorted(df["ç±»å‹"].unique())
    dom_options = sorted(df["é¢†åŸŸ"].unique())

    c1, c2 = st.columns(2)
    with c1:
        type_sel = st.multiselect("æŒ‰ç´¢å¼•ç±»å‹è¿‡æ»¤", type_options, default=type_options)
    with c2:
        dom_sel = st.multiselect("æŒ‰é¢†åŸŸè¿‡æ»¤", dom_options, default=dom_options)

    df_filtered = df[df["ç±»å‹"].isin(type_sel) & df["é¢†åŸŸ"].isin(dom_sel)]
    st.dataframe(df_filtered, use_container_width=True)

    st.markdown("#### åˆ†ç±»ç»Ÿè®¡")
    grouped = df_filtered.groupby(["é¢†åŸŸ", "ç±»å‹"], as_index=False)["æ¡ç›®æ•°"].sum()
    if grouped.empty:
        st.write("æ— åŒ¹é…çš„ç´¢å¼•ã€‚")
        return
    st.dataframe(grouped, use_container_width=True)


def render_index_manager(st, conn, cur):
    """
    ğŸ§  ç»Ÿä¸€çš„ç´¢å¼•ç®¡ç†é¡µé¢:
      - æŒ‰é¡¹ç›®æŸ¥çœ‹: è¯­æ–™æ¡æ•° / å…¶ä¸­æ¥è‡ªå†å²çš„æ¡æ•° / ç´¢å¼•æ¡æ•°æ‹†åˆ†
      - ä¸€é”®é‡å»ºå½“å‰é¡¹ç›®ç´¢å¼•
      - (å¯é€‰) æ‰¹é‡é‡å»º
    """
    st.title("ğŸ§  è¯­ä¹‰ç´¢å¼•ç®¡ç†")

    # === 1. é¡¹ç›®åˆ—è¡¨ + åŸºæœ¬ç»Ÿè®¡ ===
    st.markdown("#### é¡¹ç›®æ¦‚è§ˆ")

    rows = cur.execute(
        """
        SELECT i.id,
               IFNULL(i.title,''),
               IFNULL(i.domain,''),
               COUNT(DISTINCT c.id)                                           AS corpus_cnt,
               SUM(CASE WHEN c.note LIKE 'from trans_ext%%' THEN 1 ELSE 0 END) AS hist_cnt
        FROM items i
        LEFT JOIN corpus c ON c.project_id = i.id
        GROUP BY i.id, i.title, i.domain
        ORDER BY i.id DESC
        LIMIT 500;
        """
    ).fetchall()

    if not rows:
        st.info("å½“å‰è¿˜æ²¡æœ‰ä»»ä½•é¡¹ç›®æˆ–è¯­æ–™ã€‚è¯·å…ˆåœ¨é¡¹ç›®ç®¡ç†/è¯­æ–™åº“ä¸­æ·»åŠ å†…å®¹ã€‚")
        return

    df_proj = pd.DataFrame(
        [
            {
                "é¡¹ç›®ID": r[0],
                "é¡¹ç›®åç§°": r[1],
                "é¢†åŸŸ": r[2],
                "è¯­æ–™æ¡æ•°": r[3],
                "å…¶ä¸­æ¥è‡ªç¿»è¯‘å†å²": r[4] or 0,
            }
            for r in rows
        ]
    )

    st.dataframe(df_proj, use_container_width=True)

    # === 2. é€‰æ‹©ä¸€ä¸ªé¡¹ç›®ï¼ŒæŸ¥çœ‹ç´¢å¼•çŠ¶æ€ ===
    st.markdown("#### å•é¡¹ç›®ç´¢å¼•çŠ¶æ€ & æ“ä½œ")

    proj_options = {f"[{r[0]}] {r[1] or '(æœªå‘½å)'}": r[0] for r in rows}
    proj_label = st.selectbox(
        "é€‰æ‹©è¦æŸ¥çœ‹/é‡å»ºç´¢å¼•çš„é¡¹ç›®",
        ["(è¯·é€‰æ‹©)"] + list(proj_options.keys()),
    )
    pid_sel = proj_options.get(proj_label)

    if not pid_sel:
        st.info("è¯·é€‰æ‹©ä¸€ä¸ªé¡¹ç›®ä»¥æŸ¥çœ‹ç´¢å¼•è¯¦æƒ…ã€‚")
        return

    # 2.1 ç»Ÿè®¡å½“å‰ç´¢å¼•ä¸­çš„ source=corpus / history æ•°é‡
    idx_total = idx_corpus = idx_hist = idx_other = 0
    try:
        mode, index_obj, mapping, vecs = _load_index(int(pid_sel))
        if isinstance(mapping, list):
            idx_total = len(mapping)
            for m in mapping:
                src_tag = (m.get("source") or "").lower()
                if src_tag == "history":
                    idx_hist += 1
                elif src_tag in ("", "corpus"):
                    idx_corpus += 1
                else:
                    idx_other += 1
    except Exception as e:
        st.warning(f"è¯»å–ç´¢å¼•æ–‡ä»¶å¤±è´¥: {e}")

    st.write(
        f"- å½“å‰ç´¢å¼•æ¡æ•°: **{idx_total}** æ¡\n"
        f"- å…¶ä¸­æ¥è‡ªè¯­æ–™åº“(corpus): **{idx_corpus}** æ¡\n"
        f"- å…¶ä¸­æ¥è‡ªç¿»è¯‘å†å²(history): **{idx_hist}** æ¡\n"
        f"- å…¶ä»–/æœªçŸ¥æ¥æº: **{idx_other}** æ¡"
    )

    # 2.2 å½“å‰é¡¹ç›®åœ¨ DB ä¸­çš„è¯­æ–™ç»Ÿè®¡ï¼Œå’Œä¸Šé¢çš„ df_proj å¯¹åº”
    row_sel = [r for r in rows if r[0] == pid_sel][0]
    st.write(
        f"- æ•°æ®åº“ä¸­è¯­æ–™æ¡æ•°: **{row_sel[3]}** æ¡ "
        f"(å…¶ä¸­æ¥è‡ªç¿»è¯‘å†å²: **{row_sel[4] or 0}** æ¡)"
    )

    # === 3. æ“ä½œåŒº: é‡å»ºç´¢å¼• / æ‰¹é‡é‡å»º ===
    c1, c2 = st.columns(2)

    with c1:
        if st.button("ğŸ” é‡å»ºå½“å‰é¡¹ç›®ç´¢å¼•", type="primary", key=f"rebuild_idx_{pid_sel}"):
            res = rebuild_project_semantic_index(cur, pid_sel, split_fn=_split_pair_for_index)
            if res.get("ok"):
                st.success(
                    f"ç´¢å¼•å·²é‡å»º: æ–°å¢ {res['added']} æ¡, æ€»é‡ {res['total']} æ¡ã€‚"
                )
            else:
                st.error(f"é‡å»ºå¤±è´¥: {res.get('msg','æœªçŸ¥é”™è¯¯')}")

    with c2:
        if st.button("âš  æ‰¹é‡é‡å»ºä¸Šè¡¨åˆ—å‡ºçš„å…¨éƒ¨é¡¹ç›®ç´¢å¼•", key="rebuild_all_idx"):
            ok_cnt = fail_cnt = 0
            for r in rows:
                pid = r[0]
                res = rebuild_project_semantic_index(cur, pid, split_fn=_split_pair_for_index)
                if res.get("ok"):
                    ok_cnt += 1
                else:
                    fail_cnt += 1
            st.success(f"æ‰¹é‡é‡å»ºå®Œæˆ: æˆåŠŸ {ok_cnt} ä¸ªé¡¹ç›®, å¤±è´¥ {fail_cnt} ä¸ªé¡¹ç›®ã€‚")


def render_index_manager_by_domain(st, conn, cur):
    """æŒ‰é¢†åŸŸç®¡ç†è¯­ä¹‰ç´¢å¼•ä¸ç­–ç•¥ç´¢å¼•ã€‚"""
    st.title("ğŸ§  æŒ‰é¢†åŸŸç®¡ç†ç´¢å¼•ä¸ç­–ç•¥åº“")

    render_index_overview(st)
    st.markdown("---")

    domains = set()
    try:
        rows = cur.execute("SELECT DISTINCT IFNULL(domain,'æœªåˆ†ç±»') FROM items WHERE COALESCE(type,'')='project'").fetchall()
        for (d,) in rows:
            if d and d.strip():
                domains.add(d.strip())
            else:
                domains.add("æœªåˆ†ç±»")

        rows = cur.execute("SELECT DISTINCT IFNULL(domain,'æœªåˆ†ç±»') FROM corpus").fetchall()
        for (d,) in rows:
            if d and d.strip():
                domains.add(d.strip())
            else:
                domains.add("æœªåˆ†ç±»")

        rows = cur.execute("SELECT DISTINCT IFNULL(domain,'æœªåˆ†ç±»') FROM strategy_texts").fetchall()
        for (d,) in rows:
            if d and d.strip():
                domains.add(d.strip())
            else:
                domains.add("æœªåˆ†ç±»")
    except Exception:
        pass

    if not domains:
        st.info("å½“å‰å°šæœªè®¾ç½®ä»»ä½•é¢†åŸŸ(domain)ã€‚è¯·å…ˆåœ¨é¡¹ç›®æˆ–è¯­æ–™ä¸­è®¾ç½®é¢†åŸŸã€‚")
        return

    domains_list = sorted(domains)
    dom_sel = st.selectbox("é€‰æ‹©è¦ç®¡ç†çš„é¢†åŸŸ", domains_list)
    dom_key = (dom_sel or "").strip() or "æœªåˆ†ç±»"

    st.markdown(f"### å½“å‰é¢†åŸŸ: `{dom_key}`")

    # 2) ç»Ÿè®¡è¯¥é¢†åŸŸä¸‹çš„é¡¹ç›® & è¯­æ–™ & ç´¢å¼•æƒ…å†µ
    # 2.1 é¡¹ç›®åˆ—è¡¨
    proj_rows = cur.execute(
        "SELECT id, title FROM items WHERE IFNULL(domain,'æœªåˆ†ç±»') = ? ORDER BY id ASC",
        (dom_key,),
    ).fetchall()
    proj_ids = [pid for (pid, _) in proj_rows]

    # 2.2 è¯­æ–™æ¡æ•°(å¦‚æœ corpus æœ‰ domain å­—æ®µ)
    corpus_cnt = None
    try:
        cols = [r[1] for r in cur.execute("PRAGMA table_info(corpus)").fetchall()]
        if "domain" in cols:
            corpus_cnt = cur.execute(
                "SELECT COUNT(*) FROM corpus WHERE IFNULL(domain,'æœªåˆ†ç±»') = ?",
                (dom_key,),
            ).fetchone()[0]
    except Exception:
        corpus_cnt = None

    # 2.3 åŒè¯­ç´¢å¼•æ¡æ•° = è¯¥é¢†åŸŸæ‰€æœ‰é¡¹ç›®ç´¢å¼•çš„ mapping é•¿åº¦ä¹‹å’Œ
    idx_bilingual_total = 0
    for pid in proj_ids:
        try:
            mode, index, mapping, vecs = _load_index(int(pid))
        except Exception:
            continue
        if isinstance(mapping, list):
            idx_bilingual_total += len(mapping)

    # 2.4 ç­–ç•¥æ–‡æœ¬æ•°é‡ & ç­–ç•¥ç´¢å¼•æ¡æ•°
    try:
        strategy_cnt = cur.execute(
            "SELECT COUNT(*) FROM strategy_texts WHERE IFNULL(domain,'æœªåˆ†ç±»') = ?",
            (dom_key,),
        ).fetchone()[0]
    except Exception:
        strategy_cnt = 0

    mode_s, index_s, mapping_s, vecs_s = _load_index_domain(dom_key, "strategy")
    if isinstance(mapping_s, list):
        idx_strategy_total = len(mapping_s)
    else:
        idx_strategy_total = 0

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("#### ğŸ“˜ åŒè¯­å¯¹ç…§ç´¢å¼•(ä¾‹å¥åº“)")
        st.write(f"- è¯¥é¢†åŸŸä¸‹é¡¹ç›®æ•°: **{len(proj_ids)}**")
        if corpus_cnt is not None:
            st.write(f"- è¯­æ–™åº“ä¸­åŒè¯­æ¡ç›®(æŒ‰ domain è®¡): **{corpus_cnt}**")
        st.write(f"- å·²å»ºç«‹ç´¢å¼•çš„å¥å¯¹æ¡æ•°(åˆè®¡): **{idx_bilingual_total}**")

        if proj_ids:
            if st.button("ğŸ” é‡å»ºè¯¥é¢†åŸŸæ‰€æœ‰é¡¹ç›®çš„ã€åŒè¯­å¯¹ç…§ã€‘ç´¢å¼•", key=f"rebuild_bi_{dom_key}"):
                added_sum = 0
                total_sum = 0
                for pid in proj_ids:
                    try:
                        res = build_project_vector_index(cur, int(pid), split_fn=_split_pair_for_index)
                        added_sum += res.get("added", 0)
                        total_sum = res.get("total", total_sum)
                    except Exception as e:
                        st.warning(f"é¡¹ç›® {pid} é‡å»ºç´¢å¼•æ—¶å‡ºé”™: {e}")
                st.success(
                    f"å·²é‡å»ºè¯¥é¢†åŸŸæ‰€æœ‰é¡¹ç›®ç´¢å¼•ã€‚"
                    f"æ–°å¢å¥å¯¹: {added_sum}ï¼Œæœ€åä¸€ä¸ªé¡¹ç›®è¿”å›çš„ç´¢å¼•æ€»é‡: {total_sum}"
                )
        else:
            st.info("è¯¥é¢†åŸŸä¸‹æš‚æ—¶æ²¡æœ‰ä»»ä½•é¡¹ç›®ã€‚")

    with c2:
        st.markdown("#### ğŸ“ ç¿»è¯‘ç­–ç•¥ç´¢å¼•(strategy)")
        st.write(f"- è¯¥é¢†åŸŸä¸‹ç­–ç•¥æ–‡æœ¬æ¡æ•°: **{strategy_cnt}**")
        st.write(f"- å·²å»ºç«‹ç´¢å¼•çš„ç­–ç•¥å‘é‡æ¡æ•°: **{idx_strategy_total}**")

        if st.button("ğŸ” é‡å»ºè¯¥é¢†åŸŸçš„ã€ç¿»è¯‘ç­–ç•¥ã€‘ç´¢å¼•", key=f"rebuild_strategy_{dom_key}"):
            try:
                res = build_strategy_index_for_domain(dom_key)
                st.success(
                    f"å·²é‡å»ºç­–ç•¥ç´¢å¼•ã€‚æ–°å¢ç­–ç•¥æ®µè½: {res.get('added', 0)}ï¼Œ"
                    f"ç´¢å¼•æ€»é‡: {res.get('total', 0)}"
                )
            except Exception as e:
                st.error(f"é‡å»ºç­–ç•¥ç´¢å¼•æ—¶å‡ºé”™: {e}")

    st.markdown("---")
    with st.expander("ğŸ” æŸ¥çœ‹è¯¥é¢†åŸŸä¸‹çš„é¡¹ç›®åˆ—è¡¨", expanded=False):
        if proj_rows:
            for pid, title in proj_rows:
                st.write(f"- é¡¹ç›® {pid}: {title}")
        else:
            st.write("æš‚æ— é¡¹ç›®ã€‚")

    with st.expander("ğŸ” æŸ¥çœ‹è¯¥é¢†åŸŸä¸‹çš„ç­–ç•¥æ–‡æœ¬(å‰å‡ æ¡)", expanded=False):
        try:
            rows = cur.execute(
                "SELECT id, title, substr(content,1,200) FROM strategy_texts "
                "WHERE IFNULL(domain,'æœªåˆ†ç±»') = ? ORDER BY id DESC LIMIT 20",
                (dom_key,),
            ).fetchall()
            if not rows:
                st.write("æš‚æ— ç­–ç•¥æ–‡æœ¬ã€‚")
            else:
                for rid, title, content_prev in rows:
                    st.write(f"- #{rid} {title}: {content_prev}â€¦")
        except Exception as e:
            st.write(f"è¯»å–ç­–ç•¥æ–‡æœ¬å‡ºé”™: {e}")


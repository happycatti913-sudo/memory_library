# -*- coding: utf-8 -*-
"""
ä¸ªäººç¿»è¯‘çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿ(ä¿®æ­£ç‰ˆ03)
- Tab1 ğŸ“‚ ç¿»è¯‘é¡¹ç›®ç®¡ç†:æ–°å»ºé¡¹ç›®ã€æ–‡ä»¶ä¸Šä¼ ã€æ‰§è¡Œç¿»è¯‘(DeepSeek API).å¯¼å‡ºå¯¹ç…§/åŸæ ¼å¼.å†™å…¥å†å²
- Tab2 ğŸ“˜ æœ¯è¯­åº“ç®¡ç†:æŸ¥è¯¢/ç¼–è¾‘/åˆ é™¤ã€CSVæ‰¹é‡å¯¼å…¥ã€ç»Ÿè®¡/å¯¼å‡ºã€å¿«é€Ÿæœç´¢ã€æ‰¹é‡æŒ‚æ¥é¡¹ç›®ã€å†å²æŠ½å–æœ¯è¯­ã€åˆ†ç±»ç®¡ç†
- Tab3 ğŸ“Š ç¿»è¯‘å†å²:æŸ¥çœ‹ã€ä¸‹è½½è¯‘æ–‡
- Tab4 ğŸ“š è¯­æ–™åº“ç®¡ç†:æ–°å¢/æ£€ç´¢/åˆå¹¶/Few-shot æ³¨å…¥
"""

# ==== stdlib ====
import os
import re
import io
import sys
import json
import uuid
import time
import streamlit as st
import pandas as pd
import altair as alt

from app_core.config import BASE_DIR, KBEmbedder, dedup_terms_against_db, make_sk, _project_domain
from app_core.database import init_db
from app_core.semantic_index import _load_index, rebuild_project_semantic_index
from app_core.semantic_ops import align_semantic, semantic_retrieve
from app_core.translation_ops import get_deepseek
from app_core.term_extraction import _locate_example_pair, ds_extract_terms
from app_core.file_ops import export_csv_bilingual, export_docx_bilingual, read_source_file
from app_core.corpus_ops import import_corpus_from_upload
from app_core.ui_common import render_table
from app_core.ui_index import render_index_manager, render_index_manager_by_domain
from app_core.ui_projects import render_project_tab
from app_core.ui_terms import render_term_management
from app_core.text_utils import _split_pair_for_index, read_docx_tables_info, read_docx_text, read_pdf_text, read_txt, split_sents

# ========== é¡µé¢è®¾ç½® ==========
st.set_page_config(page_title="ä¸ªäººç¿»è¯‘çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿ3.0", layout="wide")

# ========== å·¥å…·å‡½æ•° ==========
# ======= è·å–æŸæ¡å†å²è®°å½•å¯¹åº”çš„åŸæ–‡(ä¼˜å…ˆ items.body.å…œåº• src_path ä»…ä½œä¸ºæ ‡é¢˜æç¤º)=======
# ======= å¯¹é½å¹¶å¯¼å‡º(ä¾èµ–ä½ å·²æœ‰çš„ split_blocks / align_export)=======
# ========== è·¯å¾„/DB ==========
conn, cur = init_db()

# ====== æœ¯è¯­ç®¡ç† UI ======

# ========== Session åˆå§‹åŒ– ==========
if "kb_embedder" not in st.session_state and KBEmbedder:
    st.session_state["kb_embedder"] = KBEmbedder(lazy=True)

# ========== é¡µé¢ç»“æ„ ==========
st.sidebar.title("å¯¼èˆª")

choice = st.sidebar.radio(
    "åŠŸèƒ½é€‰æ‹©",
    [
        "ğŸ“‚ ç¿»è¯‘é¡¹ç›®ç®¡ç†",
        "ğŸ“˜ æœ¯è¯­åº“ç®¡ç†",
        "ğŸ“Š ç¿»è¯‘å†å²",
        "ğŸ“š è¯­æ–™åº“ç®¡ç†",
        "ğŸ§  ç´¢å¼•ç®¡ç†",
    ],
)

st.title("ä¸ªäººç¿»è¯‘çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿ3.0")


# ========== Tab1:ç¿»è¯‘é¡¹ç›®ç®¡ç† ==========
if choice.startswith("ğŸ“‚"):
    render_project_tab(st, cur, conn, BASE_DIR)

# ========== Tab2:æœ¯è¯­åº“ç®¡ç† ==========
elif choice.startswith("ğŸ“˜"):
    render_term_management(st, cur, conn, BASE_DIR, key_prefix="term")


# ========== Tab3:ç¿»è¯‘å†å²(å¢å¼ºç‰ˆ) ==========
elif choice.startswith("ğŸ“Š"):
    st.subheader("ğŸ“Š ç¿»è¯‘å†å²è®°å½•(å¯å†™å…¥è¯­æ–™ / æŠ½å–æœ¯è¯­ / ä¸‹è½½å¯¹ç…§ / åˆ é™¤)")

    rows = cur.execute("""
        SELECT id, project_id, lang_pair,
               substr(IFNULL(output_text,''),1,120) AS prev, created_at
        FROM trans_ext
        ORDER BY datetime(created_at) DESC
        LIMIT 200
    """).fetchall()

    if not rows:
        st.info("æš‚æ— å†å²è®°å½•ã€‚")
    else:
        for rid, pid, lp, prev, ts in rows:
            # é¡¹ç›®æ ‡é¢˜(åšè¯­æ–™æ ‡é¢˜/å±•ç¤º)
            ttl_row = cur.execute("SELECT IFNULL(title,'') FROM items WHERE id=?", (pid,)).fetchone()
            proj_title = (ttl_row or [""])[0] or f"project#{pid}"
            proj_domain = _project_domain(pid, cur)

            with st.expander(f"#{rid}ï½œé¡¹ç›® {pid}ï½œ{proj_title}ï½œ{lp}ï½œ{ts}", expanded=False):
                # è¯‘æ–‡å…¨æ–‡ & æºæ–‡ä»¶è·¯å¾„
                det = cur.execute("SELECT output_text, src_path FROM trans_ext WHERE id=?", (rid,)).fetchone()
                tgt_full, src_path = det or ("", "")
                st.code(prev or "", language="text")
                st.text_area("è¯‘æ–‡å…¨æ–‡", tgt_full or "", height=220, key=f"hist_full_{rid}")

                # å°è¯•è¯»å–åŸæ–‡(å¦‚æœå½“æ—¶ä¿å­˜äº†æºæ–‡ä»¶è·¯å¾„)
                try:
                    src_full = read_source_file(src_path) if src_path else ""
                except Exception:
                    src_full = ""

                with st.expander("åŸæ–‡é¢„è§ˆ(è‹¥ä¸Šä¼ äº†æºæ–‡ä»¶)", expanded=False):
                    st.text_area("åŸæ–‡å…¨æ–‡", src_full or "(æœªä¿å­˜/æœªä¸Šä¼ æºæ–‡ä»¶)", height=160, key=f"hist_src_{rid}")

                c1, c2, c3, c4, c5 = st.columns(5)

                # 1) æ·»åŠ è¿›è¯­æ–™åº“ / æ·»åŠ +é‡å»ºç´¢å¼•
                with c1:
                    # 1-1 åªå†™å…¥è¯­æ–™åº“
                    if st.button("â• æ·»åŠ è¿›è¯­æ–™åº“", key=f"hist_add_corpus_{rid}"):
                        if not src_full and not tgt_full:
                            st.warning("åŸæ–‡å’Œè¯‘æ–‡éƒ½ä¸ºç©ºï¼Œæ— æ³•å†™å…¥è¯­æ–™åº“ã€‚")
                        else:
                            cur.execute("""
                                INSERT INTO corpus (title, project_id, lang_pair, src_text, tgt_text, note, created_at)
                                VALUES (?, ?, ?, ?, ?, ?, datetime('now'))
                            """, (
                                f"{proj_title} Â· history#{rid}",
                                pid,
                                lp or "",
                                src_full or None,
                                tgt_full or "",
                                f"from trans_ext#{rid}",
                            ))
                            conn.commit()
                            st.success("âœ… å·²å†™å…¥è¯­æ–™åº“")

                    # 1-2 å†™å…¥è¯­æ–™åº“å¹¶é‡å»ºç´¢å¼•
                    if st.button("â• æ·»åŠ å¹¶é‡å»ºç´¢å¼•", key=f"hist_add_corpus_rebuild_{rid}_{idx}"):
                        if not src_full and not tgt_full:
                            st.warning("åŸæ–‡å’Œè¯‘æ–‡éƒ½ä¸ºç©ºï¼Œæ— æ³•å†™å…¥è¯­æ–™åº“ã€‚")
                        else:
                            # å…ˆå†™å…¥è¯­æ–™åº“
                            cur.execute("""
                                INSERT INTO corpus (title, project_id, lang_pair, src_text, tgt_text, note, created_at)
                                VALUES (?, ?, ?, ?, ?, ?, datetime('now'))
                            """, (
                                f"{proj_title} Â· history#{rid}",
                                pid,
                                lp or "",
                                src_full or None,
                                tgt_full or "",
                                f"from trans_ext#{rid}",
                            ))
                            conn.commit()

                            # å†é‡å»ºè¯¥é¡¹ç›®çš„è¯­ä¹‰ç´¢å¼•
                            res_idx = rebuild_project_semantic_index(cur, pid, split_fn=_split_pair_for_index)
                            if res_idx.get("ok"):
                                st.success(
                                    f"âœ… å·²å†™å…¥è¯­æ–™åº“å¹¶é‡å»ºç´¢å¼•: æ–°å¢ {res_idx['added']} æ¡, æ€»é‡ {res_idx['total']} æ¡"
                                )
                            else:
                                st.warning(
                                    f"å·²å†™å…¥è¯­æ–™åº“ï¼Œä½†é‡å»ºç´¢å¼•å¤±è´¥: {res_idx.get('msg','æœªçŸ¥é”™è¯¯')}"
                                )

                # 2) æå–æœ¯è¯­(ä¼˜å…ˆè¯­æ–™åº“åŒæ¬¾æ¨¡å‹ï¼Œç¼ºçœå›é€€ DeepSeek)
                with c2:
                    if st.button("ğŸ§  æå–æœ¯è¯­", key=f"hist_extract_terms_{rid}"):
                        ak, model = get_deepseek()
                        if not ak:
                            st.info("æœªæ£€æµ‹åˆ° DeepSeek Keyï¼Œå°†ä»…ä½¿ç”¨è¯­æ–™åº“åŒæ¬¾æ¨¡å‹è¿›è¡ŒæŠ½å–ã€‚")

                        # åˆå¹¶åŸæ–‡+è¯‘æ–‡.æé«˜å€™é€‰è´¨é‡
                        big = ((src_full or "") + "\n" + (tgt_full or "")).strip()
                        res = ds_extract_terms(
                            big,
                            ak,
                            model,
                            src_lang="zh",
                            tgt_lang="en",
                            prefer_corpus_model=True,
                            default_domain=proj_domain,
                        )
                        res, dup_terms = dedup_terms_against_db(cur, res, pid)
                        if not res:
                            st.info("æœªæŠ½å–åˆ°æœ¯è¯­æˆ–è§£æå¤±è´¥")
                        else:
                            ins_term = ins_corpus = 0
                            for o in res:
                                domain_val = (o.get("domain") or proj_domain or "å…¶ä»–")
                                strategy_val = (o.get("strategy") or "history-extract")
                                cur.execute("""
                                    INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example)
                                    VALUES (?, ?, ?, ?, ?, ?)
                                """, (
                                    o.get("source_term") or "",
                                    (o.get("target_term") or None),
                                    domain_val,
                                    pid,
                                    strategy_val,
                                    (o.get("example") or None),
                                ))
                                ins_term += 1

                                src_ex, tgt_ex = _locate_example_pair(o.get("example"), src_full, tgt_full)
                                if src_ex:
                                    cur.execute(
                                        """
                                        INSERT INTO corpus(title, project_id, lang_pair, src_text, tgt_text, note, domain, source, created_at)
                                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
                                        """,
                                        (
                                            f"{proj_title} Â· term#{rid}",
                                            pid,
                                            lp or "",
                                            src_ex,
                                            tgt_ex,
                                            "term-example",
                                            domain_val,
                                            "history-term",
                                        ),
                                    )
                                    ins_corpus += 1
                            conn.commit()
                            msg = f"âœ… å·²å†™å…¥æœ¯è¯­åº“ {ins_term} æ¡ï¼ŒåŒæ­¥è¯­æ–™åº“ {ins_corpus} æ¡"
                            if dup_terms:
                                msg += f"ï¼›è·³è¿‡é‡å¤ {len(dup_terms)} æ¡"
                            st.success(msg)

                # 3) ä¸‹è½½åŒè¯­å¯¹ç…§(CSV / DOCX)
                with c3:
                    if st.button("â¬‡ï¸ CSV å¯¹ç…§", key=f"hist_dl_bicsv_btn_{rid}"):
                        if not src_full:
                            st.warning("æ‰¾ä¸åˆ°åŸæ–‡(æœªä¸Šä¼ æºæ–‡ä»¶).æ— æ³•ç”Ÿæˆ CSV å¯¹ç…§")
                        else:
                            try:
                                csv_name = f"bilingual_history_{rid}.csv"
                                csv_bytes = export_csv_bilingual((src_full, tgt_full),
                                    filename=f"bilingual_history_{rid}.csv"
                                )
                            except TypeError:
                                # å¦‚æœä½ çš„å¯¼å‡ºå‡½æ•°æ˜¯ textâ†’bytes ç‰ˆæœ¬
                                csv_name = f"bilingual_history_{rid}.csv"
                                csv_bytes = export_csv_bilingual(src_full, tgt_full)
                            st.download_button("ä¸‹è½½ CSV", data=csv_bytes,
                                               file_name=csv_name, mime="text/csv",
                                               key=f"hist_dl_bicsv_{rid}")

                with c4:
                    if st.button("â¬‡ï¸ DOCX å¯¹ç…§", key=f"hist_dl_bidocx_btn_{rid}"):
                        if not src_full:
                            st.warning("æ‰¾ä¸åˆ°åŸæ–‡(æœªä¸Šä¼ æºæ–‡ä»¶).æ— æ³•ç”Ÿæˆ DOCX å¯¹ç…§")
                        else:
                            try:
                                docx_path = export_docx_bilingual(
                                    filename=f"bilingual_history_{rid}.docx"
                                )
                                with open(docx_path, "rb") as f:
                                    data_docx = f.read()
                            except TypeError:
                                # å¦‚æœä½ çš„å¯¼å‡ºå‡½æ•°æ˜¯ textâ†’bytes ç‰ˆæœ¬
                                data_docx = export_docx_bilingual(src_full, tgt_full)
                            st.download_button("ä¸‹è½½ DOCX", data=data_docx,
                                               file_name=f"bilingual_history_{rid}.docx",
                                               mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                               key=f"hist_dl_bidocx_{rid}")

                # 4) ğŸ—‘ åˆ é™¤æœ¬æ¡å†å²(å®‰å…¨ç¡®è®¤)
                with c5:
                    with st.expander("ğŸ—‘ åˆ é™¤æœ¬æ¡å†å²(ä¸å¯æ¢å¤)", expanded=False):
                        st.warning("æ­¤æ“ä½œå°†æ°¸ä¹…åˆ é™¤è¯¥æ¡ trans_ext è®°å½•(ä¸å½±å“å·²å†™å…¥è¯­æ–™åº“/æœ¯è¯­è¡¨çš„æ•°æ®)ã€‚")
                        ok = st.checkbox(f"æˆ‘ç¡®è®¤åˆ é™¤ #{rid}", key=f"hist_del_ck_{rid}")
                        if st.button("ç¡®è®¤åˆ é™¤", key=f"hist_del_btn_{rid}") and ok:
                            cur.execute("DELETE FROM trans_ext WHERE id=?", (rid,))
                            conn.commit()
                            st.success("å·²åˆ é™¤.è¯·åˆ·æ–°é¡µé¢æŸ¥çœ‹ç»“æœã€‚")
                            st.stop()  # ç»ˆæ­¢æœ¬æ¬¡æ¸²æŸ“.é¿å…åœ¨å·²åˆ é™¤æ•°æ®ä¸Šç»§ç»­æ“ä½œ

                # åŸæœ‰çš„â€œä¸‹è½½è¯‘æ–‡ TXTâ€
                st.download_button("ä¸‹è½½è¯‘æ–‡ (TXT)", tgt_full or "",
                                   file_name=f"history_{rid}.txt",
                                   mime="text/plain",
                                   key=f"hist_dl_txt_{rid}")

# ========== Tab4:è¯­æ–™åº“ç®¡ç† ==========
elif choice.startswith("ğŸ“š"):
    def render_corpus_manager(st, cur, conn, pid_prefix="corpus"):
        st.header("ğŸ“š è¯­æ–™åº“ç®¡ç†")
        sk = make_sk(pid_prefix)

    render_corpus_manager(st, cur, conn)

    # åˆå§‹åŒ– Few-shot çŠ¶æ€å­—å…¸
    get_project_ref_ids(None)
    get_project_fewshot_enabled(None)
    st.session_state.setdefault("corpus_target_project", None)
    st.session_state.setdefault("corpus_target_label", "(è¯·é€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®)")

    sub = st.tabs(["æ–°å»ºè¯­æ–™", "æµè§ˆ/æ£€ç´¢", "ä½¿ç”¨ä¸å¯¼å‡º"])

    # -------- æ–°å»ºè¯­æ–™ --------
    with sub[0]:
        st.subheader("ğŸ“¥ ä¸Šä¼  / å¯¹é½ / å…¥åº“")

        colA, colB = st.columns(2)
        with colA:
            one_file = st.file_uploader("â‘  å•ä¸ªæ–‡ä»¶(DOCX è¡¨æ ¼å¯¹ç…§ / å•è¯­ DOCX/TXT/PDF)",
                                        type=["docx", "txt", "pdf"], key="up_one")
        with colB:
            two_src = st.file_uploader("â‘¡ åŸæ–‡æ–‡ä»¶(å¯é€‰:ä¸ â‘¢ æ­é…åšå¯¹é½)",
                                       type=["docx", "txt", "csv", "pdf"], key="up_src")
            two_tgt = st.file_uploader("â‘¢ è¯‘æ–‡æ–‡ä»¶(å¯é€‰:ä¸ â‘¡ æ­é…åšå¯¹é½)",
                                       type=["docx", "txt", "csv", "pdf"], key="up_tgt")

        st.divider()
        meta1, meta2, meta3 = st.columns([2, 1, 1])
        with meta1:
            title = st.text_input("è¯­æ–™æ ‡é¢˜", value="æœªå‘½åè¯­æ–™")
        with meta2:
            lp = st.selectbox("æ–¹å‘", ["è‡ªåŠ¨", "ä¸­è¯‘è‹±", "è‹±è¯‘ä¸­"])
        with meta3:
            pid_val = st.text_input("é¡¹ç›®ID(å¯ç•™ç©º)")
        pid = int(pid_val) if pid_val.strip().isdigit() else None

        ins = 0
        pairs = []
        src_text = tgt_text = ""
        preview_df = None

        # ========== è·¯å¾„ A:å•ä¸ªæ–‡ä»¶ ==========
        if one_file is not None and (two_src is None and two_tgt is None):
            ext = (one_file.name.split(".")[-1] or "").lower()
            bio = io.BytesIO(one_file.getvalue())

            if ext == "docx":
                # å…ˆå°è¯•â€œè¡¨æ ¼å¯¹ç…§â€
                tables = read_docx_tables_info(io.BytesIO(bio.getvalue()))
                if tables:
                    st.caption("æ£€æµ‹åˆ° DOCX è¡¨æ ¼ï¼Œä¼˜å…ˆä½œä¸ºåŒè¯­å¯¹ç…§å¯¼å…¥ã€‚")
                    # ç®€å•èµ·è§ï¼Œé»˜è®¤ç¬¬ 0 å¼ è¡¨çš„ç¬¬ 0/1 åˆ—;ä½ ä¹Ÿå¯ä»¥åŠ å…¥ä¸‹æ‹‰é€‰æ‹©
                    pairs = extract_pairs_from_docx_table(
                        io.BytesIO(bio.getvalue()),
                        table_index=0,
                        src_col=0,
                        tgt_col=1
                    )
                else:
                    # æ²¡æœ‰è¡¨æ ¼ â†’ å•è¯­æ–‡æœ¬
                    src_text = read_docx_text(io.BytesIO(bio.getvalue()))

            elif ext == "txt":
                src_text = read_txt(bio)

            elif ext == "pdf":
                src_text = read_pdf_text(io.BytesIO(bio.getvalue()))

        # ========== è·¯å¾„ B:ä¸¤ä¸ªæ–‡ä»¶(åŸæ–‡ + è¯‘æ–‡)==========
        elif two_src is not None and two_tgt is not None:
            def read_any(f):
                e = (f.name.split(".")[-1] or "").lower()
                b = io.BytesIO(f.getvalue())
                if e == "docx":
                    return read_docx_text(b)
                if e == "txt":
                    return read_txt(b)
                if e == "csv":
                    try:
                        df = pd.read_csv(b)
                        return "\n".join(df.iloc[:, 0].astype(str).fillna(""))
                    except Exception:
                        return ""
                if e == "pdf":
                    return read_pdf_text(b)
                return ""
            src_text = read_any(two_src)
            tgt_text = read_any(two_tgt)

        # ========== é¢„è§ˆä¸å†³å®šå…¥åº“æ–¹å¼ ==========
        # æƒ…å†µ 1:æœ‰ pairs(æ¥è‡ª DOCX è¡¨æ ¼)
        if pairs:
            st.success(f"è§£æåˆ° {len(pairs)} å¯¹(DOCX è¡¨æ ¼)")
            preview_df = pd.DataFrame(pairs[:200], columns=["æºå¥", "ç›®æ ‡å¥"])

        # æƒ…å†µ 2:æ²¡æœ‰ pairsï¼Œä½†æ‹¿åˆ°äº† src/tgt æ–‡æœ¬ â†’ åˆ‡å¥/å¯¹é½
        elif src_text and tgt_text:
            sents_src = split_sents(src_text, "zh" if lp.startswith("ä¸­") else "auto")
            sents_tgt = split_sents(tgt_text, "en" if lp.startswith("è‹±") else "auto")
            st.caption(f"å°†å¯¹é½: src={len(sents_src)}  tgt={len(sents_tgt)}")
            if st.button("ğŸ” æ‰§è¡Œè¯­ä¹‰å¯¹é½", key="do_align"):
                pairs_aligned = align_semantic(sents_src, sents_tgt, max_jump=5)
                st.info(f"å¯¹é½å¾—åˆ° {len(pairs_aligned)} å¯¹")
                pairs = [(s, t) for (s, t, score) in pairs_aligned]
                if pairs:
                    preview_df = pd.DataFrame(pairs[:200], columns=["æºå¥", "ç›®æ ‡å¥"])

        # æƒ…å†µ 3:åªæœ‰å•è¯­æ–‡æœ¬(PDF/DOCX/TXT)
        elif src_text and not tgt_text:
            sents_src = split_sents(src_text, "zh" if lp.startswith("ä¸­") else "auto")
            st.info(f"æ£€æµ‹åˆ°å•è¯­æ–‡æœ¬ï¼Œå…± {len(sents_src)} å¥ã€‚å°†ä»¥å•è¯­è¯­æ–™å†™å…¥(è¯‘æ–‡ä¸ºç©º)ã€‚")
            preview_df = pd.DataFrame(
                [{"æºå¥": s, "ç›®æ ‡å¥": ""} for s in sents_src[:200]]
            )

        if preview_df is not None:
            st.dataframe(preview_df, width='stretch')

        # â€”â€” æŒ‰é’® + é€‰é¡¹:å¯¼å…¥è¯­æ–™åº“ | åŒæ—¶é‡å»ºç´¢å¼•
        c_imp, c_opt, c_build = st.columns([1, 1, 1])
        do_import = c_imp.button("ğŸ“¥ å†™å…¥è¯­æ–™åº“", type="primary", key="write_pairs_btn")
        do_build_opt = c_opt.checkbox("å¯¼å…¥åç«‹å³é‡å»ºç´¢å¼•", value=True, key="build_vec_opt")
        only_build_now = c_build.button("ğŸ§  ä»…é‡å»ºç´¢å¼•(ä¸å¯¼å…¥)", key="only_build")

        st.caption("æç¤º: ç´¢å¼•ä¹Ÿå¯ä»¥ç¨ååœ¨â€œä½¿ç”¨ä¸ç´¢å¼• / å¯¼å‡ºâ€é¡µçš„ C åŒºç»Ÿä¸€é‡å»ºã€‚")

        # ===== è¿™é‡Œå¼€å§‹ç”¨ç»Ÿä¸€ç®¡çº¿ =====
        # ç»Ÿä¸€ç®—ä¸€ä¸ªå…œåº•æ ‡é¢˜ï¼ˆä¼˜å…ˆç”¨ç•Œé¢ä¸Šçš„ titleï¼Œå†ç”¨æ–‡ä»¶åï¼‰
        default_title = ""
        if one_file is not None:
            default_title = one_file.name
        elif two_src is not None:
            default_title = two_src.name

        if do_import:
            import_corpus_from_upload(
                st,
                cur,
                conn,
                pid=pid,              # ä½ ä¸Šé¢ meta åŒºçš„é¡¹ç›® ID
                title=title,          # ä½ ä¸Šé¢è¾“å…¥çš„è¯­æ–™æ ‡é¢˜
                lp=lp,                # æ–¹å‘é€‰æ‹©
                pairs=pairs,
                src_text=src_text,
                tgt_text=tgt_text,
                default_title=default_title,
                build_after_import=do_build_opt,
            )

        if only_build_now:
            # ä»…é‡å»ºå½“å‰é¡¹ç›®çš„è¯­ä¹‰ç´¢å¼•(ä¸å¯¼å…¥æ–°è¯­æ–™)
            if pid:
                res_idx = rebuild_project_semantic_index(cur, pid, split_fn=_split_pair_for_index)
                if res_idx.get("ok"):
                    st.success(
                        f"ğŸ§  ç´¢å¼•å·²é‡å»º: æ–°å¢ {res_idx['added']}ï¼Œæ€»é‡ {res_idx['total']}ã€‚"
                    )
                else:
                    st.error(f"é‡å»ºå¤±è´¥: {res_idx.get('msg','æœªçŸ¥é”™è¯¯')}")
            else:
                st.warning("è¯·å…ˆåœ¨ä¸Šæ–¹å¡«å†™æœ‰æ•ˆçš„é¡¹ç›®IDï¼Œå†é‡å»ºç´¢å¼•ã€‚")

    # -------- æµè§ˆ/æ£€ç´¢ --------
    with sub[1]:
        st.subheader("ğŸ” æµè§ˆ/æ£€ç´¢")
        k1, k2, k3 = st.columns([2, 1, 1])
        with k1:
            kw = st.text_input("å…³é”®è¯(æ ‡é¢˜/å¤‡æ³¨/è¯‘æ–‡)", "", key=sk("kw"))
        with k2:
            lp_filter = st.selectbox("æ–¹å‘è¿‡æ»¤", ["å…¨éƒ¨", "ä¸­è¯‘è‹±", "è‹±è¯‘ä¸­", "è‡ªåŠ¨"], key=sk("lp_filter"))
        with k3:
            limit = st.number_input("æ¡æ•°", min_value=10, max_value=1000, value=200, step=10, key=sk("limit"))

        sql = """
        SELECT id, title, IFNULL(project_id,''), IFNULL(lang_pair,''), 
               substr(IFNULL(tgt_text,''),1,80), created_at
        FROM corpus
        WHERE 1=1
        """
        params = []
        if kw.strip():
            like = f"%{kw.strip()}%"
            sql += " AND (title LIKE ? OR IFNULL(note,'') LIKE ? OR IFNULL(tgt_text,'') LIKE ?)"
            params.extend([like, like, like])
        if lp_filter != "å…¨éƒ¨":
            sql += " AND lang_pair=?"
            params.append(lp_filter)
        sql += " ORDER BY id DESC LIMIT ?"
        params.append(int(limit))

        rows = cur.execute(sql, params).fetchall()
        if not rows:
            st.info("æš‚æ— åŒ¹é…è¯­æ–™ã€‚")

        else:
            for rid, ttl, pj, lpv, prev, ctime in rows:
                with st.expander(f"[{rid}] {ttl} | é¡¹ç›®:{pj} | æ–¹å‘:{lpv} | {ctime}"):
                    st.write(f"**ID**: {rid}  **é¡¹ç›®ID**: {pj}  **æ–¹å‘**: {lpv}  **æ—¶é—´**: {ctime}")
                    st.write(f"**é¢„è§ˆ(è¯‘æ–‡å‰80å­—)**: {prev}")
                    det = cur.execute(
                        "SELECT IFNULL(src_text,''), IFNULL(tgt_text,'') FROM corpus WHERE id=?",
                        (rid,)
                    ).fetchone()
                    src_all, tgt_all = det or ("", "")
                    st.text_area("æºæ–‡", src_all, height=160, key=sk(f"src_{rid}"))
                    st.text_area("è¯‘æ–‡", tgt_all, height=160, key=sk(f"tgt_{rid}"))

                    c1, c2, c3, c4 = st.columns(4)
                    with c1:
                        if st.button("åŠ å…¥å‚è€ƒé›†åˆ", key=sk(f"add_ref_{rid}")):
                            target_pid = st.session_state.get("corpus_target_project")
                            if not target_pid:
                                st.warning("è¯·å…ˆåœ¨ä¸Šæ–¹é€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®ï¼Œå†æ·»åŠ å‚è€ƒè¯­æ–™ã€‚")
                            else:
                                refs = get_project_ref_ids(target_pid)
                                refs.add(int(rid))
                                st.success(f"âœ… å·²åŠ å…¥é¡¹ç›® #{target_pid} çš„å‚è€ƒé›†åˆ(â€œä½¿ç”¨ä¸å¯¼å‡ºâ€æŸ¥çœ‹)")
                    with c2:
                        if st.button("å¯¼å‡ºTXT", key=sk(f"cor_txt_{rid}")):
                            st.download_button(
                                "ä¸‹è½½è¯‘æ–‡TXT",
                                tgt_all or "",
                                file_name=f"corpus_{rid}.txt",
                                mime="text/plain",
                                key=sk(f"cor_txt_dl_{rid}")
                            )
                    with c3:
                        if st.button("å¯¼å‡ºCSV(ä¸­è‹±å¯¹ç…§)", key=sk(f"cor_csv_{rid}")):
                            df_out = pd.DataFrame(
                                [{"source": src_all, "target": tgt_all}]
                            )
                            csv_data = df_out.to_csv(index=False)
                            st.download_button(
                                "ä¸‹è½½CSV",
                                csv_data,
                                file_name=f"corpus_{rid}.csv",
                                mime="text/csv",
                                key=sk(f"cor_csv_dl_{rid}")
                            )
                    with c4:
                        if st.button("åˆ é™¤", key=sk(f"del_{rid}")):
                            cur.execute("DELETE FROM corpus WHERE id=?", (rid,))
                            conn.commit()
                            st.warning("ğŸ—‘ï¸ å·²åˆ é™¤ï¼Œåˆ·æ–°åç”Ÿæ•ˆ")
                            st.rerun()

    # -------- ä½¿ç”¨ä¸å¯¼å‡º --------
    with sub[2]:
        st.subheader("ğŸ§© ä½¿ç”¨ä¸ç´¢å¼• / å¯¼å‡º")

        proj_rows = cur.execute("SELECT id, IFNULL(title,'(æœªå‘½å)') FROM items WHERE COALESCE(type,'')='project' ORDER BY id DESC LIMIT 200").fetchall()
        proj_options = {"(è¯·é€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®)": None}
        proj_options.update({f"[{pid}] {ttl}": pid for pid, ttl in proj_rows})
        option_labels = list(proj_options.keys())
        saved_label = st.session_state.get("corpus_target_label")
        if saved_label not in option_labels:
            saved_label = option_labels[0]
        selection_label = st.selectbox(
            "Few-shot å‚è€ƒé›†åˆå°†ç»‘å®šåˆ°å“ªä¸ªé¡¹ç›®ï¼Ÿ",
            option_labels,
            index=option_labels.index(saved_label),
            key="corpus_proj_select",
        )
        st.session_state["corpus_target_label"] = selection_label
        st.session_state["corpus_target_project"] = proj_options.get(selection_label)
        if st.session_state["corpus_target_project"]:
            st.caption(f"å½“å‰ Few-shot ç›®æ ‡: {selection_label}")
        else:
            st.caption("æœªé€‰æ‹©é¡¹ç›®:è¯·å…ˆåœ¨æ­¤æŒ‡å®šç›®æ ‡é¡¹ç›®ï¼Œå†å»å…¶ä»–å­é¡µæ·»åŠ å‚è€ƒç¤ºä¾‹ã€‚")

        # A åŒº:å‚è€ƒé›†åˆåˆå¹¶ä¸å¯¼å‡º
        target_pid = st.session_state.get("corpus_target_project")
        if not target_pid:
            st.info("è¯·å…ˆé€šè¿‡é¡µé¢ä¸Šæ–¹çš„ä¸‹æ‹‰æ¡†é€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®ï¼Œå†ç®¡ç†å‚è€ƒé›†åˆã€‚")
        else:
            ids = sorted({int(x) for x in get_project_ref_ids(target_pid)}, reverse=True)
            st.caption(f"é¡¹ç›® #{target_pid} çš„å·²é€‰å‚è€ƒæ•°: {len(ids)}")
            if ids:
                qmarks = ",".join(["?"] * len(ids))
                dets = cur.execute(
                    f"SELECT id, title, lang_pair, IFNULL(src_text,''), IFNULL(tgt_text,'') "
                    f"FROM corpus WHERE id IN ({qmarks})",
                    ids
                ).fetchall()
                order_map = {rid: idx for idx, rid in enumerate(ids)}
                dets.sort(key=lambda row: order_map.get(row[0], len(order_map)))
                merged_demo = "\n\n---\n\n".join(
                    [f"\n\næºæ–‡:\n{src}\n\nè¯‘æ–‡:\n{tgt}" for (_, _, _, src, tgt) in dets]
                )
                st.text_area("åˆå¹¶é¢„è§ˆ", merged_demo, height=240, key=sk("merge_preview"))

                cxa, cxb = st.columns(2)
                with cxa:
                    if st.button("æ¸…ç©ºå‚è€ƒé›†åˆ", key=sk(f"clear_refs_{target_pid}")):
                        refs = get_project_ref_ids(target_pid)
                        refs.clear()
                        st.info(f"å·²æ¸…ç©ºé¡¹ç›® #{target_pid} çš„å‚è€ƒé›†åˆ")
                with cxb:
                    if st.button("å¯¼å‡ºå‚è€ƒTXT", key=sk(f"export_refs_txt_{target_pid}")):
                        st.download_button(
                            "ä¸‹è½½TXT",
                            merged_demo,
                            file_name=f"corpus_refs_{target_pid}.txt",
                            mime="text/plain",
                            key=sk(f"export_refs_txt_dl_{target_pid}")
                        )
            else:
                st.info("è¿˜æ²¡æœ‰é€‰æ‹©ä»»ä½•å‚è€ƒè¯­æ–™ï¼Œå¯ä»¥åœ¨â€œæµè§ˆ/æ£€ç´¢â€ä¸­å‹¾é€‰åå†æ¥ã€‚")

        st.markdown("---")

        # B åŒº:Few-shot æ³¨å…¥å¼€å…³
        if not target_pid:
            st.info("é€‰æ‹©ç›®æ ‡é¡¹ç›®åæ‰èƒ½é…ç½® Few-shot æ³¨å…¥å¼€å…³ã€‚")
            use_fs = False
        else:
            curr_state = get_project_fewshot_enabled(target_pid)
            use_fs = st.checkbox(
                "ç¿»è¯‘æ—¶è‡ªåŠ¨æ³¨å…¥è¿™äº›å‚è€ƒè¯­æ–™ä½œä¸º Few-shot æç¤º",
                value=curr_state,
                key=sk(f"use_fs_{target_pid}")
            )
        if st.button("ä¿å­˜å‚è€ƒæ³¨å…¥å¼€å…³", key=sk("save_fs")):
            if not target_pid:
                st.warning("è¯·å…ˆé€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®")
            else:
                set_project_fewshot_enabled(target_pid, use_fs)
                st.success(
                    f"å·²æ›´æ–°:é¡¹ç›® #{target_pid} "
                    + ("å°†æ³¨å…¥å‚è€ƒ few-shot" if use_fs else "ä¸ä¼šè‡ªåŠ¨æ³¨å…¥å‚è€ƒ")
                )

        st.markdown("---")

        # C åŒº:é¡¹ç›®çº§ç´¢å¼•ç®¡ç† + è¯­ä¹‰å¬å›æµ‹è¯•
        st.subheader("ğŸ§  è¯­ä¹‰ç´¢å¼•ç®¡ç† & å¬å›æµ‹è¯•")

        # é€‰æ‹©é¡¹ç›®
        proj_rows = cur.execute(
            """
            SELECT id, title
            FROM items
            WHERE COALESCE(type,'')='project'
            ORDER BY id DESC
            LIMIT 200
            """
        ).fetchall()
        proj_map = {"(è¯·é€‰æ‹©)": None}
        proj_map.update({f"[{i}] {t}": i for (i, t) in proj_rows})
        proj_sel = st.selectbox("é€‰æ‹©è¦æµ‹è¯•/é‡å»ºç´¢å¼•çš„é¡¹ç›®", list(proj_map.keys()), key=sk("vec_proj"))
        pid_sel = proj_map.get(proj_sel)
        # æ˜¾ç¤ºå½“å‰é¡¹ç›®ç´¢å¼•ä¸­ corpus / history ç»Ÿè®¡
        idx_total = idx_corpus = idx_hist = idx_other = 0
        if pid_sel:
            try:
                mode, index_obj, mapping, vecs = _load_index(int(pid_sel))
                if isinstance(mapping, list):
                    idx_total = len(mapping)
                    for m in mapping:
                        src_tag = (m.get("source") or "").lower()
                        if src_tag == "history":
                            idx_hist += 1
                        elif src_tag in ("", "corpus"):
                            idx_corpus += 1
                        else:
                            idx_other += 1
            except Exception:
                # ç´¢å¼•æ–‡ä»¶æŸå/ä¸å­˜åœ¨æ—¶ç›´æ¥å¿½ç•¥ç»Ÿè®¡
                pass

        if pid_sel:
            st.caption(
                f"å½“å‰ç´¢å¼•æ¡æ•°: {idx_total} æ¡ "
                f"(è¯­æ–™åº“: {idx_corpus} æ¡, æ¥è‡ªç¿»è¯‘å†å²: {idx_hist} æ¡, å…¶ä»–: {idx_other} æ¡)ã€‚"
            )
        else:
            st.caption("è¯·é€‰æ‹©é¡¹ç›®ä»¥æŸ¥çœ‹è¯¥é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€ã€‚")


        c_build1, c_build2 = st.columns(2)
        with c_build1:
            if st.button("æ„å»º/æ›´æ–°è¯¥é¡¹ç›®ç´¢å¼•", key=sk("build_idx_btn")):
                if pid_sel:
                    res_idx = rebuild_project_semantic_index(cur, pid_sel, split_fn=_split_pair_for_index)
                    if res_idx.get("ok"):
                        st.success(
                            f"ç´¢å¼•å·²æ›´æ–°: æ–°å¢ {res_idx['added']}ï¼Œæ€»é‡ {res_idx['total']}ã€‚"
                        )
                    else:
                        st.error(f"æ„å»ºå¤±è´¥: {res_idx.get('msg','æœªçŸ¥é”™è¯¯')}")
                else:
                    st.warning("è¯·å…ˆé€‰æ‹©å…·ä½“é¡¹ç›®ã€‚")

        with c_build2:
            st.caption("è¯´æ˜:ç´¢å¼•ç”¨äºè¯­ä¹‰å¬å›å‚è€ƒä¾‹å¥ï¼Œç¿»è¯‘æ—¶ç”±ç³»ç»Ÿè‡ªåŠ¨è°ƒç”¨ã€‚")

        q_demo = st.text_area("è¯•æœä¸€å¥è¯(å°†ä»¥è¯­ä¹‰ç›¸ä¼¼æ£€ç´¢å‚è€ƒ)", "", height=80, key=sk("q_demo"))
        topk = st.number_input("Top-K", 1, 10, 5, key=sk("q_topk"))
        if st.button("ğŸ” è¯­ä¹‰å¬å›æµ‹è¯•", key=sk("q_vec")):
            if pid_sel and q_demo.strip():
                hits = semantic_retrieve(pid_sel, q_demo.strip(), topk=int(topk), cur=cur)
                if not hits:
                    st.info("ç´¢å¼•ä¸ºç©ºæˆ–æœªå‘½ä¸­ã€‚è¯·å…ˆæ„å»ºç´¢å¼•æˆ–å¢åŠ è¯­æ–™ã€‚")
                else:
                    for row in hits:
                        sc, m, txt = row[:3]   # åªæ‹¿å‰ 3 ä¸ªï¼Œåé¢å¤šä½™çš„å¿½ç•¥
                        st.write(f"**{sc:.3f}** | {m.get('title','')} | {m.get('lang_pair','')}")
                        st.code(txt, language="text")
                        st.markdown("---")
            else:
                st.warning("è¯·å…ˆé€‰æ‹©é¡¹ç›®å¹¶è¾“å…¥è¦æ£€ç´¢çš„å†…å®¹ã€‚")

elif choice.startswith("ğŸ§ "):
    render_index_manager_by_domain(st, conn, cur)


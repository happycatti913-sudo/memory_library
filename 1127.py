# -*- coding: utf-8 -*-
"""
ä¸ªäººç¿»è¯‘çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿ(ä¿®æ­£ç‰ˆ03)
- Tab1 ğŸ“‚ ç¿»è¯‘é¡¹ç›®ç®¡ç†:æ–°å»ºé¡¹ç›®ã€æ–‡ä»¶ä¸Šä¼ ã€æ‰§è¡Œç¿»è¯‘(DeepSeek API).å¯¼å‡ºå¯¹ç…§/åŸæ ¼å¼.å†™å…¥å†å²
- Tab2 ğŸ“˜ æœ¯è¯­åº“ç®¡ç†:æŸ¥è¯¢/ç¼–è¾‘/åˆ é™¤ã€CSVæ‰¹é‡å¯¼å…¥ã€ç»Ÿè®¡/å¯¼å‡ºã€å¿«é€Ÿæœç´¢ã€æ‰¹é‡æŒ‚æ¥é¡¹ç›®ã€å†å²æŠ½å–æœ¯è¯­ã€åˆ†ç±»ç®¡ç†
- Tab3 ğŸ“Š ç¿»è¯‘å†å²:æŸ¥çœ‹ã€ä¸‹è½½è¯‘æ–‡
- Tab4 ğŸ“š è¯­æ–™åº“ç®¡ç†:æ–°å¢/æ£€ç´¢/åˆå¹¶/Few-shot æ³¨å…¥
"""

# ==== stdlib ====
import os
import re
import io
import sys
import json
import uuid
import time
import streamlit as st
import pandas as pd
import altair as alt

from app_core.config import (
    BASE_DIR,
    DB_PATH,
    LOG_DIR,
    LOG_FILE,
    Document,
    KBEmbedder,
    build_prompt_soft,
    build_prompt_strict,
    dedup_terms_against_db,
    highlight_terms,
    log_event,
    make_sk,
    recommend_for_segment,
    sk,
    _norm_domain_key,
    _project_domain,
)
from app_core.database import ensure_col, init_db, _get_domain_for_proj, _has_col
from app_core.projects import (
    cleanup_project_files,
    ensure_legacy_file_record,
    get_project_fewshot_enabled,
    get_project_fewshot_examples,
    get_project_ref_ids,
    fetch_project_files,
    register_project_file,
    remove_project_file,
    set_project_fewshot_enabled,
)
from app_core.semantic_index import (
    _lazy_import_vec,
    _load_index,
    _load_index_domain,
    _save_index,
    _save_index_domain,
    build_project_vector_index,
    build_strategy_index_for_domain,
    get_embedder,
    quick_diagnose_vectors,
    rebuild_project_semantic_index,
)
from app_core.semantic_ops import (
    _build_ref_context,
    align_semantic,
    semantic_consistency_report,
    semantic_retrieve,
)
from app_core.term_ops import check_term_consistency, get_terms_for_project
from app_core.translation_ops import (
    build_instruction,
    build_term_hint,
    ds_translate,
    get_deepseek,
    translate_block_with_kb,
)
from app_core.term_extraction import (
    _locate_example_pair,
    _split_sentences_for_terms,
    ds_extract_terms,
    extract_terms_with_corpus_model,
)
from app_core.file_ops import export_csv_bilingual, export_docx_bilingual, read_source_file
from app_core.corpus_ops import import_corpus_from_upload
from app_core.ui_common import render_table
from app_core.ui_index import render_index_manager, render_index_manager_by_domain
from app_core.text_utils import (
    _lazy_docx,
    _normalize,
    _split_pair_for_index,
    build_bilingual_lines,
    extract_pairs_from_docx_table,
    pair_paragraphs,
    read_docx_tables_info,
    read_docx_text,
    read_pdf_text,
    read_txt,
    split_blocks,
    split_paragraphs,
    split_sents,
)

# ========== é¡µé¢è®¾ç½® ==========
st.set_page_config(page_title="ä¸ªäººç¿»è¯‘çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿ3.0", layout="wide")

# ========== å·¥å…·å‡½æ•° ==========
# ======= è·å–æŸæ¡å†å²è®°å½•å¯¹åº”çš„åŸæ–‡(ä¼˜å…ˆ items.body.å…œåº• src_path ä»…ä½œä¸ºæ ‡é¢˜æç¤º)=======
def run_project_translation_ui(
    pid,
    project_title,
    src_path,
    conn,
    cur
):
    """
    æ‰§è¡Œç¿»è¯‘æ•´ä¸ª UI + é€»è¾‘ã€‚ä¸æ”¹é€»è¾‘ï¼Œåªæ˜¯æŠŠåŸæ¥ Tab1 é‡Œçš„å¤§å—æ¬è¿›æ¥ã€‚
    å‚æ•°å«ä¹‰ï¼š
        pid: å½“å‰é¡¹ç›® ID
        project_title: é¡¹ç›®æ ‡é¢˜
        src_path: æºæ–‡ä»¶è·¯å¾„æˆ–æ–‡æœ¬å†…å®¹
        conn, cur: æ•°æ®åº“å¥æŸ„
    """

    st.subheader(f"ğŸ“˜ é¡¹ç›®ï¼š{project_title}")
    st.info("æ‰“å·¥ä¸æ˜“ï¼Œç‰›é©¬å“­æ³£ã€‚")

    # å…ˆç»Ÿä¸€åŠ è½½æœ¯è¯­ï¼ˆé™æ€ + åŠ¨æ€ï¼‰
    term_map, term_meta = get_terms_for_project(cur, pid, use_dynamic=True)
    proj_terms_all = term_map  # ç»™ _detect_hits ç”¨

    # 1) ç»“æœç¼“å­˜åˆå§‹åŒ–(ç»Ÿä¸€ç”¨ session_state)
    if "all_results" not in st.session_state:
        st.session_state["all_results"] = []
    st.session_state["all_results"].clear()

    # 2) ç¯å¢ƒæ£€æŸ¥
    ak, model = get_deepseek()
    if not ak:
        st.error("æœªæ£€æµ‹åˆ° DeepSeek Key.è¯·åœ¨ `.streamlit/secrets.toml` é…ç½® [deepseek]")
        st.stop()
    if not selected_src_path or not os.path.exists(selected_src_path):
        st.error("ç¼ºå°‘æºæ–‡ä»¶")
        st.stop()

    # 3) è¯»å–ä¸åˆ†æ®µ
    src_text = read_source_file(selected_src_path)
    st.code(repr(src_text[:400]))                     # çœ‹å­—ç¬¦ä¸²é‡Œæœ‰æ²¡æœ‰ '\n'
    st.write({"len": len(src_text), "nl": src_text.count("\n"), "cr": src_text.count("\r")})
    st.write({"preview_lines": src_text.splitlines()[:3]})
    
    # ç”¨ç»Ÿä¸€çš„ split_paragraphs åšåˆ‡åˆ†
    blocks = split_paragraphs(src_text)
    if not blocks:
        st.error("æºæ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œæˆ–æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ®µè½")
        st.stop()

    st.info(f"æŒ‰æ®µè½åˆ‡åˆ†ï¼Œå…± {len(blocks)} æ®µï¼Œå¼€å§‹ç¿»è¯‘â€¦")

    lang_pair_val = st.session_state.get(f"lang_{pid}", "ä¸­è¯‘è‹±")
    use_semantic  = bool(st.session_state.get(f"use_sem_{pid}", True))
    scope_val     = st.session_state.get(f"scope_{pid}", st.session_state.get("scope_newproj", "project"))

    # 4) å¾ªç¯ç¿»è¯‘ï¼ˆç»Ÿä¸€èµ° translate_block_with_kb ç®¡çº¿ï¼‰
    # å…ˆåŠ è½½ few-shot ç¤ºä¾‹ï¼ˆé¡¹ç›®çº§ï¼‰
    fewshot_examples = get_project_fewshot_examples(cur, pid, limit=5)
    if fewshot_examples:
        with st.expander("ğŸ“Œ Few-shot å‚è€ƒç¤ºä¾‹(é¡¹ç›®çº§æ³¨å…¥)", expanded=False):
            for ex in fewshot_examples:
                st.markdown(
                    f"**{ex['title']}**\n\næºæ–‡:\n{ex['src']}\n\nè¯‘æ–‡:\n{ex['tgt']}\n---"
                )

    # ä¸ºæ¯æ¬¡ç¿»è¯‘å‡†å¤‡ä¸€ä¸ªç»“æœåˆ—è¡¨
    if "all_results" not in st.session_state:
        st.session_state["all_results"] = []
    st.session_state["all_results"].clear()

    # DeepSeek key / model åªå–ä¸€æ¬¡
    ak, model = get_deepseek()
    if not ak:
        st.error("æœªæ£€æµ‹åˆ° DeepSeek Key.è¯·åœ¨ `.streamlit/secrets.toml` é…ç½® [deepseek]")
        st.stop()

    # æŒ‰æ®µå¾ªç¯ç¿»è¯‘
    for i, blk in enumerate(blocks, start=1):
        blk = str(blk or "").strip()
        if not blk:
            continue

        # â€”â€” è°ƒç”¨ç»Ÿä¸€ç®¡çº¿å®Œæˆâ€œæœ¯è¯­ + å‚è€ƒ + DeepSeekâ€ â€”â€” 
        out_text = res["tgt"]
        term_map_all = res["term_map_all"]
        terms_in_block = res.get("terms_in_block", {})
        terms_corpus = res.get("terms_corpus_dyn", {})
        terms_final = res.get("terms_final", {})
        ref_context = res["ref_context"]
        violated = res["violated_terms"]

        # â€”â€” å±•ç¤ºæœ¯è¯­ + å‚è€ƒä¾‹å¥ï¼ˆæŠ˜å ï¼Œå¯é€‰ï¼‰â€”â€”
        with st.expander(f"ç¬¬ {i} æ®µ Â· æœ¯è¯­ä¸å‚è€ƒï¼ˆå¯é€‰å±•å¼€ï¼‰", expanded=False):
            if term_map_all:
                df_all = pd.DataFrame(
                    [
                        {
                            "æœ¯è¯­": s,
                            "è¯‘æ–‡": t,
                            "å‘½ä¸­æœ¬æ®µ": s in terms_in_block,
                            "å‘½ä¸­å‚è€ƒä¾‹å¥": s in terms_corpus,
                            "æœ€ç»ˆæ³¨å…¥Prompt": s in terms_final,
                        }
                        for s, t in term_map_all.items()
                    ]
                )
                st.dataframe(df_all, width='stretch')

                # å•ç‹¬åˆ—å‡ºâ€œè¯­æ–™é©±åŠ¨æœ¯è¯­â€ï¼ˆæ–¹ä¾¿ä½ çœ‹ï¼‰
                corpus_only = [
                    {"æœ¯è¯­": s, "è¯‘æ–‡": t}
                    for s, t in terms_corpus.items()
                ]
                if corpus_only:
                    st.markdown("**è¯­æ–™é©±åŠ¨æœ¯è¯­ï¼ˆä»…åœ¨å‚è€ƒä¾‹å¥ä¸­å‘½ä¸­çš„æœ¯è¯­ï¼‰ï¼š**")
                    st.dataframe(pd.DataFrame(corpus_only), width='stretch')

            if ref_context:
                st.text(ref_context[:1500])

        # è®°å½•ç»“æœ(ç»Ÿä¸€ç”¨ session_state)
        st.session_state["all_results"].append(out_text)
        st.write(f"âœ… ç¬¬ {i} æ®µå®Œæˆ")

        # è¯‘åä¸€è‡´æ€§æé†’
        if violated:
            st.warning("ä»¥ä¸‹æœ¯è¯­æœªåœ¨è¯‘æ–‡ä¸­å‡ºç°(å»ºè®®äººå·¥æ ¸å¯¹): " + "ï¼›".join(violated))


    # ===== å¾ªç¯ç»“æŸå:æ±‡æ€»è¾“å‡º =====

    # ç»“æœä¸æºæ®µè½å…œåº•ä¸å¯¹é½
    all_results_safe = list(st.session_state.get("all_results", []))
    blocks_src_safe  = list(blocks if 'blocks' in locals() else [])
    if len(blocks_src_safe) != len(all_results_safe):
        n = min(len(blocks_src_safe), len(all_results_safe))
        blocks_src_safe  = blocks_src_safe[:n]
        all_results_safe = all_results_safe[:n]

    # æ–‡æœ¬æ±‡æ€»
    final_text = "\n\n".join(all_results_safe)

    # ä¸€è‡´æ€§æŠ¥å‘Š(è¯­ä¹‰+æœ¯è¯­)
    try:
        term_map_report, _ = get_terms_for_project(cur, pid, use_dynamic=True)
        df_rep = semantic_consistency_report(
            project_id=pid,
            blocks_src=blocks_src_safe,
            blocks_tgt=all_results_safe,
            term_map=term_map_report,
            topk=3,
            thr=0.70,
            cur=cur,
        )
        st.markdown("### ğŸ” è¯‘åä¸€è‡´æ€§æŠ¥å‘Š(è¯­ä¹‰+æœ¯è¯­)")
        st.dataframe(df_rep, width='stretch')
    except Exception as e:
        st.caption(f"(ä¸€è‡´æ€§æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e})")

    # ä¸‹è½½æŒ‰é’®(TXT)
    proj_title = (title if 'title' in locals() and title else f"project_{pid}")
    st.download_button(
        "â¬‡ï¸ ä¸‹è½½ç¿»è¯‘ç»“æœ (TXT)",
        final_text or "",
        file_name=f"{proj_title}_ç¿»è¯‘ç»“æœ.txt",
        mime="text/plain",
        key=f"dl_txt_{pid}"
    )

    # å†™å…¥å†å² trans_ext
    try:
        # å…¼å®¹å–å€¼(éƒ½åšäº†å…œåº•.é˜²æ­¢æœªå®šä¹‰)
        src_path = selected_src_path if ('selected_src_path' in locals() and selected_src_path) else None
        mode_val = mode if ('mode' in locals() and mode) else "æ ‡å‡†æ¨¡å¼"
        lang_pair_val = st.session_state.get(f"lang_{pid}", "ä¸­è¯‘è‹±")

        # è®¡ç®—æ®µæ•°:å»ºè®®ä»¥ã€Œæºæ–‡æœ¬ã€ç»Ÿè®¡ï¼›è‹¥æ— åˆ™é€€å›æœ€ç»ˆè¯‘æ–‡
        src_for_seg = src_text if ('src_text' in locals() and src_text) else final_text
        seg_count = len(split_sents(src_for_seg, lang_hint="auto"))

        cur.execute("""
            INSERT INTO trans_ext (
                project_id, src_path, lang_pair, mode, output_text,
                stats_json, segments, term_hit_total, created_at
            )
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
        """, (
            pid,             # é¡¹ç›®ID
            src_path,        # æºæ–‡ä»¶è·¯å¾„(å¯ä¸ºç©º)
            lang_pair_val,   # è¯­å¯¹
            mode_val,        # æ¨¡å¼
            final_text,      # è¾“å‡ºæ–‡æœ¬(æœ€ç»ˆè¯‘æ–‡)
            None,            # ç»Ÿè®¡JSON(å ä½)
            seg_count,       # æ®µæ•°(ä¿®å¤:ä¸ç”¨ blocks_src_safe)
            None             # æœ¯è¯­å‘½ä¸­æ•°(å ä½.å¯åç»­å¡«çœŸå®å€¼)
        ))
        conn.commit()
        st.success("ğŸ“ å·²å†™å…¥ç¿»è¯‘å†å²")
    except Exception as e:
        st.warning(f"å†™å…¥ç¿»è¯‘å†å²å¤±è´¥: {e}")
            

# ======= å¯¹é½å¹¶å¯¼å‡º(ä¾èµ–ä½ å·²æœ‰çš„ split_blocks / align_export)=======
# ========== è·¯å¾„/DB ==========
conn, cur = init_db()

# ====== æœ¯è¯­ç®¡ç† UI ======

def render_term_management(st, cur, conn, base_dir, key_prefix="term"):
    sk = make_sk(key_prefix)

    st.subheader("ğŸ“˜ æœ¯è¯­åº“ç®¡ç†")
    sub_tabs = st.tabs(["æŸ¥è¯¢ä¸ç¼–è¾‘", "æ‰¹é‡å¯¼å…¥ CSV", "ç»Ÿè®¡ä¸å¯¼å‡º", "å¿«é€Ÿæœç´¢", "æ‰¹é‡æŒ‚æ¥é¡¹ç›®", "ä»å†å²æå–æœ¯è¯­", "åˆ†ç±»ç®¡ç†"])

    # â€”â€” æŸ¥è¯¢ä¸ç¼–è¾‘
    with sub_tabs[0]:
        sk0 = lambda name: f"{key_prefix}_t0_{name}"

        c1, c2, c3, c4 = st.columns(4)
        with c1: kw = st.text_input("å…³é”®è¯(æº/ç›®æ ‡/ä¾‹å¥)", "", key=sk("kw_example"))
        with c2: dom = st.text_input("é¢†åŸŸ", "", key=sk("dom"))
        with c3: strat = st.text_input("ç­–ç•¥", "", key=sk("strat"))
        with c4: pid = st.text_input("é¡¹ç›®IDè¿‡æ»¤", "", key=sk("pid"))
        cat = st.text_input("åˆ†ç±»(æ”¯æŒå­ä¸²)", "", key=sk("cat"))

        # â€”â€” å…¼å®¹è€åº“:å¦‚æ—  category åˆ—åˆ™è¡¥åˆ—(å·²æœ‰ä¼šå¿½ç•¥)
        try:
            cur.execute("ALTER TABLE term_ext ADD COLUMN category TEXT;")
            conn.commit()
        except Exception:
            pass

        # 1) ä»¥æ•°æ®åº“çœŸå®åˆ—ä¸ºå‡†æ£€æµ‹æ˜¯å¦å­˜åœ¨ category
        cols_db = [c[1].lower() for c in cur.execute("PRAGMA table_info(term_ext);").fetchall()]
        has_category = ("category" in cols_db)

        # 2) æ‹¼ SQL(åªåœ¨ DB çœŸçš„æœ‰è¯¥åˆ—æ—¶æ‰ SELECT category)
        base_cols = "id, source_term, target_term, domain, project_id, strategy, example"
        sel_cols = base_cols + (", category" if has_category else "")
        sql = f"SELECT {sel_cols} FROM term_ext WHERE 1=1"
        params = []

        if kw:
            like = f"%{kw}%"
            sql += " AND (IFNULL(source_term,'') LIKE ? OR IFNULL(target_term,'') LIKE ? OR IFNULL(example,'') LIKE ?)"
            params += [like, like, like]

        if dom:
            sql += " AND IFNULL(domain,'') LIKE ?"
            params += [f"%{dom}%"]

        if strat:
            sql += " AND IFNULL(strategy,'') LIKE ?"
            params += [f"%{strat}%"]

        if pid and str(pid).isdigit():
            sql += " AND IFNULL(project_id,0) = ?"
            params += [int(pid)]

        if has_category and cat:
            sql += " AND IFNULL(category,'') LIKE ?"
            params += [f"%{cat}%"]

        sql += " ORDER BY source_term COLLATE NOCASE LIMIT 1000"

        # 3) æŸ¥è¯¢å¹¶æ„é€  DataFrame(è¡¨å¤´ä¸å®é™…åˆ—å¯¹é½)
        rows = cur.execute(sql, params).fetchall()
        headers = ["ID","æºæœ¯è¯­","ç›®æ ‡æœ¯è¯­","é¢†åŸŸ","é¡¹ç›®ID","ç­–ç•¥","ä¾‹å¥"]
        if has_category:
            headers.append("åˆ†ç±»")

        df = pd.DataFrame(rows, columns=headers)
        st.caption(f"å½“å‰æŸ¥è¯¢è¿”å›:{len(df)} æ¡")

        # 4) ç©ºæ•°æ®å°±ä¸æ¸²æŸ“ç¼–è¾‘å™¨
        if df.empty:
            st.info("æ²¡æœ‰åŒ¹é…çš„æœ¯è¯­ã€‚")
        else:
            # === ç”¨ session_state ç»´æŠ¤â€œå½“å‰è¡¨æ ¼â€ï¼Œå«é€‰æ‹©åˆ— ===
            editor_df_key = sk0("editor_df")   # ä¸“é—¨å­˜ DataFrame
            editor_key    = sk0("editor")      # data_editor å°éƒ¨ä»¶æœ¬èº«

            # åˆå§‹åŒ– / å°ºå¯¸å˜åŒ–æ—¶é‡ç½®
            if editor_df_key not in st.session_state:
                work_df = df.copy()
                if "sel" not in work_df.columns:
                    work_df.insert(0, "sel", False)
                st.session_state[editor_df_key] = work_df
            else:
                work_df = st.session_state[editor_df_key]
                if len(work_df) != len(df):
                    work_df = df.copy()
                    if "sel" not in work_df.columns:
                        work_df.insert(0, "sel", False)
                    st.session_state[editor_df_key] = work_df

            # åŠ¨æ€æ„å»ºåˆ—é…ç½®.åªæœ‰å½“ DB çœŸæœ‰â€œåˆ†ç±»â€æ—¶æ‰åŠ å…¥
            col_cfg = {
                "ID": st.column_config.NumberColumn("ID", disabled=True),
                "sel": st.column_config.CheckboxColumn("é€‰æ‹©"),
                "æºæœ¯è¯­": "æºæœ¯è¯­",
                "ç›®æ ‡æœ¯è¯­": "ç›®æ ‡æœ¯è¯­",
                "é¢†åŸŸ": "é¢†åŸŸ",
                "é¡¹ç›®ID": st.column_config.NumberColumn("é¡¹ç›®ID", step=1, required=False),
                "ç­–ç•¥": "ç­–ç•¥",
                "ä¾‹å¥": st.column_config.TextColumn("ä¾‹å¥"),
            }
            if has_category:
                col_cfg["åˆ†ç±»"] = st.column_config.TextColumn("åˆ†ç±»")

            # çœŸæ­£çš„ç¼–è¾‘å™¨:ä»¥ session_state é‡Œçš„ DataFrame ä¸ºå‡†
            edited = st.data_editor(
                st.session_state[editor_df_key],
                num_rows="dynamic",
                key=editor_key,
                column_config=col_cfg,
            )
            # æŠŠç”¨æˆ·è¿™æ¬¡ç¼–è¾‘ç»“æœå†™å› session_state
            st.session_state[editor_df_key] = edited

            c1, c2, c3 = st.columns([1, 1, 2])

            # ---------------- ä¿å­˜ä¿®æ”¹ ----------------
            with c1:
                if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹", type="primary", key=sk("save_terms")):
                    updated = inserted = 0
                    for _, row in edited.iterrows():
                        if pd.notna(row["ID"]):  # æ›´æ–°
                            if has_category:
                                cur.execute("""
                                    UPDATE term_ext
                                    SET source_term=?, target_term=?, domain=?, project_id=?, strategy=?, example=?, category=?
                                    WHERE id=?;
                                """, (
                                    (row["æºæœ¯è¯­"] or "").strip(),
                                    (row["ç›®æ ‡æœ¯è¯­"] or None),
                                    (row["é¢†åŸŸ"] or None),
                                    (int(row["é¡¹ç›®ID"]) if pd.notna(row["é¡¹ç›®ID"]) else None),
                                    (row["ç­–ç•¥"] or None),
                                    (row["ä¾‹å¥"] or None),
                                    (row.get("åˆ†ç±»") or None),
                                    int(row["ID"])
                                ))
                            else:
                                cur.execute("""
                                    UPDATE term_ext
                                    SET source_term=?, target_term=?, domain=?, project_id=?, strategy=?, example=?
                                    WHERE id=?;
                                """, (
                                    (row["æºæœ¯è¯­"] or "").strip(),
                                    (row["ç›®æ ‡æœ¯è¯­"] or None),
                                    (row["é¢†åŸŸ"] or None),
                                    (int(row["é¡¹ç›®ID"]) if pd.notna(row["é¡¹ç›®ID"]) else None),
                                    (row["ç­–ç•¥"] or None),
                                    (row["ä¾‹å¥"] or None),
                                    int(row["ID"])
                                ))
                            updated += cur.rowcount
                        else:  # æ–°å¢
                            if str(row["æºæœ¯è¯­"]).strip():
                                if has_category:
                                    cur.execute("""
                                        INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example, category)
                                        VALUES (?, ?, ?, ?, ?, ?, ?)
                                    """, (
                                        (row["æºæœ¯è¯­"] or "").strip(),
                                        (row["ç›®æ ‡æœ¯è¯­"] or None),
                                        (row["é¢†åŸŸ"] or None),
                                        (int(row["é¡¹ç›®ID"]) if pd.notna(row["é¡¹ç›®ID"]) else None),
                                        (row["ç­–ç•¥"] or None),
                                        (row["ä¾‹å¥"] or None),
                                        (row.get("åˆ†ç±»") or None)
                                    ))
                                else:
                                    cur.execute("""
                                        INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example)
                                        VALUES (?, ?, ?, ?, ?, ?)
                                    """, (
                                        (row["æºæœ¯è¯­"] or "").strip(),
                                        (row["ç›®æ ‡æœ¯è¯­"] or None),
                                        (row["é¢†åŸŸ"] or None),
                                        (int(row["é¡¹ç›®ID"]) if pd.notna(row["é¡¹ç›®ID"]) else None),
                                        (row["ç­–ç•¥"] or None),
                                        (row["ä¾‹å¥"] or None),
                                    ))
                                inserted += 1
                    conn.commit()
                    st.success(f"âœ… å·²ä¿å­˜:æ›´æ–° {updated} æ¡.æ–°å¢ {inserted} æ¡ã€‚")
                    st.rerun()

            # ---------------- å…¨é€‰ / æ¸…ç©º / åˆ é™¤ ----------------
            with c2:
                cc2a, cc2b, cc2c = st.columns([1, 1, 2])
                # è¿™é‡Œç»Ÿä¸€æ“ä½œ session_state é‡Œçš„ DataFrame
                cur_df = st.session_state[editor_df_key]

                if cc2a.button("å…¨é€‰", key=sk("sel_all")):
                    cur_df.loc[:, "sel"] = True
                    st.session_state[editor_df_key] = cur_df
                    st.rerun()

                if cc2b.button("æ¸…ç©º", key=sk("sel_clear")):
                    cur_df.loc[:, "sel"] = False
                    st.session_state[editor_df_key] = cur_df
                    st.rerun()

                if cc2c.button("ğŸ—‘ï¸ åˆ é™¤å·²å‹¾é€‰", key=sk("del_sel")):
                    to_delete = cur_df[(cur_df["sel"] == True) & pd.notna(cur_df["ID"])]["ID"].astype(int).tolist()
                    if not to_delete:
                        st.warning("æœªå‹¾é€‰ä»»ä½•è®°å½•")
                    else:
                        cur.executemany("DELETE FROM term_ext WHERE id=?", [(i,) for i in to_delete])
                        conn.commit()
                        st.success(f"ğŸ—‘ï¸ å·²åˆ é™¤ {len(to_delete)} æ¡")
                        st.rerun()

                with c3:
                    proj_opts = cur.execute(
                        "SELECT id, title FROM items WHERE COALESCE(type,'')='project' ORDER BY id DESC"
                    ).fetchall()
                    proj_map = {"(ä¸æŒ‚æ¥/ç½®ç©º)": None, **{f"#{i} {t}": i for (i, t) in proj_opts}}

                    cc3a, cc3b = st.columns([2, 1])
                    target_proj_label = cc3a.selectbox("æ‰¹é‡æŒ‚æ¥åˆ°é¡¹ç›®", list(proj_map.keys()), key=sk("bind_proj_sel"))
                    if cc3b.button("æ‰§è¡ŒæŒ‚æ¥", type="primary", key=sk("bind_apply")):
                        if "ID" in edited.columns:
                            to_update = edited[(edited["sel"] == True) & pd.notna(edited["ID"])]["ID"].astype(int).tolist()
                        else:
                            to_update = []
                        if not to_update:
                            st.warning("æœªå‹¾é€‰ä»»ä½•è®°å½•")
                        else:
                            pid_val = proj_map.get(target_proj_label)
                            q_marks = ",".join("?" for _ in to_update)
                            cur.execute(f"UPDATE term_ext SET project_id=? WHERE id IN ({q_marks})", (pid_val, *to_update))
                            conn.commit()
                            st.success(f"âœ… å·²æŒ‚æ¥ {len(to_update)} æ¡åˆ°é¡¹ç›®:{target_proj_label or '(ç©º)'}")
                            st.rerun()

            st.markdown("### å•æ¡æ–°å¢ / ç¼–è¾‘")
            with st.form(sk0("term_edit")):
                col1, col2, col3 = st.columns(3)
                with col1:
                    rid_edit = st.text_input("è¦ç¼–è¾‘çš„è®°å½• ID(ç•™ç©ºåˆ™æ–°å¢)", "", key=sk("rid_edit"))
                    source_term = st.text_input("æºè¯­è¨€æœ¯è¯­(å¿…å¡«)*", key=sk("source_term"))
                    target_term = st.text_input("ç›®æ ‡è¯­è¨€æœ¯è¯­", key=sk("target_term"))
                with col2:
                    domain = st.text_input("é¢†åŸŸ", key=sk("domain"))
                    project_id = st.text_input("é¡¹ç›®ID(å¯ç©º)", key=sk("project_id"))
                    strategy = st.text_input("ç­–ç•¥(ç›´è¯‘/æ„è¯‘/è½¬è¯‘/éŸ³è¯‘/çœç•¥/å¢è¯‘/è§„èŒƒåŒ–â€¦)", key=sk("strategy"))
                with col3:
                    example = st.text_area("ä¾‹å¥", height=80, key=sk("example"))
                    category = st.text_input("åˆ†ç±»(å¯é€‰)", key=sk("category"))

                b1, b2 = st.columns(2)
                add = b1.form_submit_button("ä¿å­˜(æ–°å¢æˆ–æ›´æ–°)")
                delbtn = b2.form_submit_button("åˆ é™¤(æŒ‰ ID)")

            if add:
                if not source_term.strip():
                    st.error("æºæœ¯è¯­å¿…å¡«")
                else:
                    if rid_edit and rid_edit.isdigit():
                        if _has_col("term_ext", "category"):
                            cur.execute("""
                            UPDATE term_ext
                            SET source_term=?, target_term=?, domain=?, project_id=?, strategy=?, example=?, category=?
                            WHERE id=?;
                            """, (source_term.strip(), target_term.strip() or None, domain or None,
                                int(project_id) if project_id.isdigit() else None, strategy or None, example or None,
                                category or None, int(rid_edit)))
                        else:
                            cur.execute("""
                            UPDATE term_ext
                            SET source_term=?, target_term=?, domain=?, project_id=?, strategy=?, example=?
                            WHERE id=?;
                            """, (source_term.strip(), target_term.strip() or None, domain or None,
                                int(project_id) if project_id.isdigit() else None, strategy or None, example or None,
                                int(rid_edit)))
                        conn.commit(); st.success("âœ… å·²æ›´æ–°"); st.rerun()
                    else:
                        if _has_col("term_ext", "category"):
                            cur.execute("""
                            INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example, category)
                            VALUES (?, ?, ?, ?, ?, ?, ?)
                            """, (
                                source_term.strip(),
                                (target_term.strip() or None) if target_term else None,
                                (domain or None),
                                (int(project_id) if project_id.isdigit() else None) if project_id else None,
                                (strategy or None),
                                (example or None),
                                (category or None)
                            ))
                        else:
                            cur.execute("""
                            INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example)
                            VALUES (?, ?, ?, ?, ?, ?)
                            """, (
                                source_term.strip(),
                                (target_term.strip() or None) if target_term else None,
                                (domain or None),
                                (int(project_id) if project_id.isdigit() else None) if project_id else None,
                                (strategy or None),
                                (example or None),
                            ))
                        conn.commit(); st.success("âœ… å·²æ–°å¢"); st.rerun()

            if delbtn:
                if rid_edit and rid_edit.isdigit():
                    cur.execute("DELETE FROM term_ext WHERE id=?", (int(rid_edit),))
                    conn.commit(); st.success("ğŸ—‘ï¸ å·²åˆ é™¤"); st.rerun()
                else:
                    st.error("è¯·å¡«å†™è¦åˆ é™¤çš„ ID")

    # â€”â€” æ‰¹é‡å¯¼å…¥ CSV(å¢å¼ºç‰ˆ:åˆ—åè§„èŒƒåŒ– / åŠ¨æ€å¸¦æˆ–ä¸å¸¦ category / å»é‡æˆ–Upsert / é€è¡Œå®¹é”™)
    with sub_tabs[1]:
        sk1 = lambda n: f"{key_prefix}_t1_{n}"
        st.caption("CSV æ¨èåˆ—:source_term, target_term, domain, project_id, strategy, example(å¯é€‰:category / åˆ†ç±»)")
        up = st.file_uploader("ä¸Šä¼  CSV æ–‡ä»¶", type=["csv"], key=sk1("csv"))

        # å°å·¥å…·:è¡¥åˆ— + å”¯ä¸€ç´¢å¼• + è§„èŒƒå‡½æ•°
        def _ensure_col(table, col, type_):
            try:
                cur.execute(f"ALTER TABLE {table} ADD COLUMN {col} {type_};")
                conn.commit()
            except Exception:
                pass

        def _ensure_unique_index():
            try:
                cur.execute("""
                CREATE UNIQUE INDEX IF NOT EXISTS ux_term_proj
                ON term_ext(LOWER(TRIM(source_term)), IFNULL(project_id,-1));
                """)
                conn.commit()
            except Exception:
                pass

        def _norm_cols(df):
            # åˆ—å:å»BOM/ä¸¤ç«¯ç©ºæ ¼ -> å°å†™ -> æ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿ -> ä¸­è‹±åˆ—åæ˜ å°„
            df.columns = [str(c).replace("\ufeff","").strip() for c in df.columns]
            df.columns = [c.lower().replace(" ", "_") for c in df.columns]
            mapping = {
                "æºæœ¯è¯­": "source_term", "source": "source_term",
                "ç›®æ ‡æœ¯è¯­": "target_term", "target": "target_term",
                "é¢†åŸŸ": "domain",
                "é¡¹ç›®id": "project_id", "é¡¹ç›®_id": "project_id",
                "ç­–ç•¥": "strategy",
                "ä¾‹å¥": "example",
                "åˆ†ç±»": "category",
            }
            df = df.rename(columns={k.lower(): v for k, v in mapping.items()})
            return df

        def _norm(v):
            if v is None: return None
            v = str(v).strip().replace("\u3000", " ")
            return v if v else None

        def _to_int(v):
            try:
                return int(v) if v is not None and str(v).strip() != "" else None
            except Exception:
                return None

        if up is not None:
            try:
                df_up = pd.read_csv(up, encoding="utf-8-sig")
            except Exception:
                df_up = pd.read_csv(up, encoding="utf-8", errors="ignore")

            df_up = _norm_cols(df_up)
            st.write("æ£€æµ‹åˆ°åˆ—:", list(df_up.columns))
            render_table(df_up.head(10), key=sk("csv_preview"))

            # DB ä¾§ç¡®ä¿æœ‰ category åˆ—(å…¼å®¹è€åº“;è‹¥å·²æœ‰ä¼šå¿½ç•¥)
            _ensure_col("term_ext", "category", "TEXT")

            # ä¾§è¾¹é€‰é¡¹
            c1, c2, c3 = st.columns(3)
            with c1:
                dedup = st.checkbox("å»é‡(æºæœ¯è¯­+é¡¹ç›®ID)", value=True, key=sk1("dedup"))
            with c2:
                use_upsert = st.checkbox("å·²å­˜åœ¨åˆ™æ›´æ–°(Upsert)", value=False, key=sk1("upsert"))
            with c3:
                skip_empty = st.checkbox("è·³è¿‡ç©ºè¯‘æ–‡", value=False, key=sk1("skip_empty"))

            # Upsert éœ€è¦å”¯ä¸€ç´¢å¼•
            if use_upsert:
                _ensure_unique_index()

            if st.button("å¯¼å…¥æœ¯è¯­åº“", key=sk1("import_btn")):
                # æ˜¯å¦åŒ…å« category åˆ—(ä»¥CSVä¸ºå‡†;DBå·²æœ‰ä¸å¼ºåˆ¶CSVå¿…é¡»æœ‰)
                has_category_col = ("category" in df_up.columns)

                # å»é‡ç¼“å­˜(ä»…åœ¨éUpsertæ¨¡å¼ä¸‹ä½¿ç”¨)
                existing = set()
                if dedup and not use_upsert:
                    rows_exist = cur.execute("""
                        SELECT LOWER(TRIM(source_term)), IFNULL(project_id,-1)
                        FROM term_ext
                    """).fetchall()
                    existing = set(rows_exist)

                ins = skp = upd = 0
                errors = []

                for idx, row in df_up.iterrows():
                    src = _norm(row.get("source_term"))
                    if not src:
                        skp += 1
                        continue

                    tgt = _norm(row.get("target_term"))
                    if skip_empty and not tgt:
                        skp += 1
                        continue

                    dom = _norm(row.get("domain"))
                    pid = _to_int(row.get("project_id"))
                    stg = _norm(row.get("strategy"))
                    exa = _norm(row.get("example"))
                    cat = _norm(row.get("category")) if has_category_col else None

                    try:
                        if use_upsert:
                            # Upsert åˆ†æ”¯(éœ€è¦å”¯ä¸€ç´¢å¼•)
                            if has_category_col:
                                cur.execute("""
                                INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example, category)
                                VALUES (?,?,?,?,?,?,?)
                                ON CONFLICT(LOWER(TRIM(source_term)), IFNULL(project_id,-1))
                                DO UPDATE SET
                                    target_term=COALESCE(excluded.target_term, term_ext.target_term),
                                    domain     =COALESCE(excluded.domain,      term_ext.domain),
                                    strategy   =COALESCE(excluded.strategy,    term_ext.strategy),
                                    example    =COALESCE(excluded.example,     term_ext.example),
                                    category   =COALESCE(excluded.category,    term_ext.category);
                                """, (src, tgt, dom, pid, stg, exa, cat))
                            else:
                                cur.execute("""
                                INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example)
                                VALUES (?,?,?,?,?,?)
                                ON CONFLICT(LOWER(TRIM(source_term)), IFNULL(project_id,-1))
                                DO UPDATE SET
                                    target_term=COALESCE(excluded.target_term, term_ext.target_term),
                                    domain     =COALESCE(excluded.domain,      term_ext.domain),
                                    strategy   =COALESCE(excluded.strategy,    term_ext.strategy),
                                    example    =COALESCE(excluded.example,     term_ext.example);
                                """, (src, tgt, dom, pid, stg, exa))
                            upd += 1  # è®¡ä¸ºâ€œå¤„ç†æˆåŠŸâ€.ä¸åŒºåˆ†æ–°æ—§
                        else:
                            # é Upsert:å»é‡(æºæœ¯è¯­+é¡¹ç›®ID)
                            key = (src.lower(), pid if pid is not None else -1)
                            if dedup and key in existing:
                                skp += 1
                                continue

                            if has_category_col:
                                cur.execute("""
                                    INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example, category)
                                    VALUES (?,?,?,?,?,?,?)
                                """, (src, tgt, dom, pid, stg, exa, cat))
                            else:
                                cur.execute("""
                                    INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example)
                                    VALUES (?,?,?,?,?,?)
                                """, (src, tgt, dom, pid, stg, exa))
                            ins += 1
                            if dedup:
                                existing.add(key)

                    except Exception as e:
                        errors.append((idx+1, src, str(e)))
                        skp += 1
                        continue

                conn.commit()

                # ç»“æœæç¤º
                if use_upsert:
                    st.success(f"âœ… å·²å¤„ç† {ins+upd} æ¡(å…¶ä¸­å¯èƒ½å«æ–°å¢+æ›´æ–°).è·³è¿‡ {skp} æ¡ã€‚")
                else:
                    st.success(f"âœ… æ–°å¢ {ins} æ¡.è·³è¿‡ {skp} æ¡ã€‚")

                if errors:
                    with st.expander("â— è¡Œçº§é”™è¯¯æ˜ç»†(ä¸å½±å“å…¶ä»–è¡Œå†™å…¥)", expanded=False):
                        for i, s, e in errors:
                            st.write(f"ç¬¬ {i} è¡Œ({s}):{e}")


    # â€”â€” ç»Ÿè®¡ä¸å¯¼å‡º
    with sub_tabs[2]:
        sk2 = lambda n: f"{key_prefix}_t2_{n}"
        st.markdown("#### æœ¯è¯­ç»Ÿè®¡")
        df_stats = pd.read_sql_query("SELECT strategy, domain, category FROM term_ext WHERE source_term IS NOT NULL", conn)
        if df_stats.empty:
            st.info("æœ¯è¯­åº“ä¸ºç©º.è¯·å…ˆæ·»åŠ æˆ–å¯¼å…¥")
        else:
            # ç»Ÿä¸€é¢„å¤„ç†ï¼šç©ºå€¼ â†’ æœªæ ‡æ³¨
            df_stats["strategy"] = df_stats["strategy"].fillna("æœªæ ‡æ³¨").replace("", "æœªæ ‡æ³¨")
            df_stats["domain"]   = df_stats["domain"].fillna("æœªæ ‡æ³¨").replace("", "æœªæ ‡æ³¨")

            # é€‰æ‹©ç»Ÿè®¡ç»´åº¦
            dim_label = st.selectbox(
                "ç»Ÿè®¡ç»´åº¦",
                ["æŒ‰é¢†åŸŸ (domain)", "æŒ‰ç¿»è¯‘ç­–ç•¥ (strategy)"],
                index=0,
                key=sk2("dim_sel"),
            )

            if "é¢†åŸŸ" in dim_label:
                dim_col = "domain"
                dim_title = "é¢†åŸŸ"
            else:
                dim_col = "strategy"
                dim_title = "ç¿»è¯‘ç­–ç•¥"

            # é€‰æ‹©å±•ç¤ºæ–¹å¼
            chart_type = st.radio(
                "å±•ç¤ºæ–¹å¼",
                ["æŸ±çŠ¶å›¾", "é¥¼å›¾", "æ•°æ®è¡¨"],
                index=0,
                horizontal=True,
                key=sk2("chart_type"),
            )

            # åšè®¡æ•°
            count_df = (
                df_stats.groupby(dim_col)[dim_col]
                .count()
                .reset_index(name="term_count")
                .sort_values("term_count", ascending=False)
            )

            # ===== ä¸åŒå±•ç¤ºæ–¹å¼ =====
            if chart_type == "æŸ±çŠ¶å›¾":
                st.markdown(f"**{dim_title} åˆ†å¸ƒï¼ˆæŸ±çŠ¶å›¾ï¼‰**")

                chart = (
                    alt.Chart(count_df)
                    .mark_bar()
                    .encode(
                        x=alt.X("term_count:Q", title="æœ¯è¯­æ•°é‡"),
                        y=alt.Y(f"{dim_col}:N", sort="-x", title=dim_title),
                        tooltip=[dim_col, "term_count"],
                    )
                    .properties(height=320)
                )
                st.altair_chart(chart, width='stretch')

            elif chart_type == "é¥¼å›¾":
                st.markdown(f"**{dim_title} åˆ†å¸ƒï¼ˆé¥¼å›¾ï¼‰**")

                chart = (
                    alt.Chart(count_df)
                    .mark_arc()
                    .encode(
                        theta=alt.Theta("term_count:Q", title="æœ¯è¯­æ•°é‡"),
                        color=alt.Color(f"{dim_col}:N", title=dim_title),
                        tooltip=[dim_col, "term_count"],
                    )
                    .properties(height=320)
                )
                st.altair_chart(chart, width='stretch')

            else:  # æ•°æ®è¡¨
                st.markdown(f"**{dim_title} åˆ†å¸ƒï¼ˆæ•°æ®è¡¨ï¼‰**")
                tbl = count_df.rename(
                    columns={
                        dim_col: dim_title,
                        "term_count": "æœ¯è¯­æ•°é‡",
                    }
                )
                render_table(tbl, hide_index=True, key=sk2("tbl"))

        st.markdown("---")
        st.markdown("#### å¯¼å‡ºæœ¯è¯­è¡¨")
        df_exp = pd.read_sql_query("""
            SELECT source_term AS 'æºæœ¯è¯­',
                   target_term AS 'ç›®æ ‡æœ¯è¯­',
                   domain AS 'é¢†åŸŸ',
                   strategy AS 'ç¿»è¯‘ç­–ç•¥',
                   example AS 'ç¤ºä¾‹å¥',
                   category AS 'åˆ†ç±»'
            FROM term_ext ORDER BY source_term COLLATE NOCASE
        """, conn)

        from io import BytesIO
        buff = BytesIO()
        with pd.ExcelWriter(buff, engine="xlsxwriter") as writer:
            df_exp.to_excel(writer, index=False, sheet_name="æœ¯è¯­åº“")
        st.download_button("ğŸ“¥ ä¸‹è½½ Excel",
                           buff.getvalue(),
                           file_name="terms.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                           key=sk2("dl_terms"))

    # â€”â€” å¿«é€Ÿæœç´¢
    with sub_tabs[3]:
        sk3 = lambda n: f"{key_prefix}_t3_{n}"
        q = st.text_input("å¿«é€Ÿæœç´¢(å‰ç¼€/å­ä¸²)", "", key=sk3("q"))
        limit = st.number_input("è¿”å›ä¸Šé™", 1, 5000, 1000, 100, key=sk3("limit"))
        if st.button("æœç´¢", key=sk3("q_btn")):
            if q:
                like = f"%{q}%"
                rows = cur.execute("""
                    SELECT id, source_term, target_term, domain, project_id
                    FROM term_ext
                    WHERE source_term LIKE ? OR target_term LIKE ?
                    ORDER BY id DESC
                    LIMIT ?
                """, (like, like, int(limit))).fetchall()
                render_table(pd.DataFrame(rows, columns=["ID","æºæœ¯è¯­","ç›®æ ‡æœ¯è¯­","é¢†åŸŸ","é¡¹ç›®"]),
                             key=sk3("q_grid"),editable=True)
            else:
                st.warning("è¯·è¾“å…¥å…³é”®è¯")

    # â€”â€” æ‰¹é‡æŒ‚æ¥é¡¹ç›®
    with sub_tabs[4]:
        sk4 = lambda n: f"{key_prefix}_t4_{n}"
        st.caption("å°†ä¸€æ‰¹æœ¯è¯­ç»Ÿä¸€è®¾ç½® project_id.ä¾¿äºé¡¹ç›®å†…ä¼˜å…ˆåŒ¹é…")
        ids_txt = st.text_area("æœ¯è¯­IDåˆ—è¡¨(é€—å·/ç©ºæ ¼/æ¢è¡Œåˆ†éš”)", key=sk4("ids"))
        pid_to = st.text_input("ç›®æ ‡é¡¹ç›®ID", key=sk4("pid_to"))
        if st.button("æ‰¹é‡æŒ‚æ¥", key=sk4("batch_btn")):
            import re
            if not pid_to.isdigit():
                st.error("é¡¹ç›®IDéœ€ä¸ºæ•°å­—")
            else:
                raw = re.split(r"[,\s]+", ids_txt.strip())
                ids = [int(x) for x in raw if x.isdigit()]
                if not ids:
                    st.warning("æœªè¯†åˆ«åˆ°æœ‰æ•ˆID")
                else:
                    qmarks = ",".join(["?"]*len(ids))
                    cur.execute(f"UPDATE term_ext SET project_id=? WHERE id IN ({qmarks})", (int(pid_to), *ids))
                    conn.commit()
                    st.success(f"âœ… å·²æŒ‚æ¥ {len(ids)} æ¡åˆ°é¡¹ç›® {pid_to}")

    # â€”â€” ä»å†å²æå–æœ¯è¯­
    with sub_tabs[5]:
        sk5 = lambda n: f"{key_prefix}_t5_{n}"
        st.markdown("#### ä»ç¿»è¯‘å†å²è®°å½•æŠ½å–æœ¯è¯­(DeepSeek)")
        ak, model = get_deepseek()
        if not ak:
            st.info("æœªæ£€æµ‹åˆ° DeepSeek Keyï¼Œå°†ç›´æ¥ä½¿ç”¨è¯­æ–™åº“åŒæ¬¾æ¨¡å‹åšç»“æ„åŒ–æœ¯è¯­æŠ½å–ã€‚")

        mode_pick = st.radio(
            "é€‰æ‹©æ¥æº",
            ["æŒ‰é¡¹ç›®æŠ½å–(åˆå¹¶å¤šæ¡)", "æŒ‰å•æ¡è®°å½•æŠ½å–"],
            horizontal=True,
            key=sk5("ext_mode"),
        )
        if mode_pick == "æŒ‰é¡¹ç›®æŠ½å–(åˆå¹¶å¤šæ¡)":
            pid_ext = st.text_input("é¡¹ç›®ID", key=sk5("ext_pid"))
            max_chars = st.number_input("é‡‡æ ·æœ€å¤§å­—ç¬¦æ•°", 1000, 20000, 5000, 500, key=sk5("ext_max"))
            if st.button("å¼€å§‹æŠ½å–", key=sk5("ext_go_proj")):
                if pid_ext.isdigit():
                    rows = cur.execute(
                        "SELECT src_path, output_text FROM trans_ext WHERE project_id=? ORDER BY id DESC LIMIT 10",
                        (int(pid_ext),),
                    ).fetchall()
                    buf = []
                    total = 0
                    for sp, ot in rows:
                        src = read_source_file(sp) if sp else ""
                        txt = (src + "\n" + (ot or "")).strip()
                        if not txt:
                            continue
                        if total + len(txt) > int(max_chars):
                            remain = max(0, int(max_chars) - total)
                            buf.append(txt[:remain])
                            break
                        else:
                            buf.append(txt)
                            total += len(txt)
                    big = "\n\n".join(buf)
                    big = "\n\n".join(buf)

                    # âœ… å…ˆçœ‹è¿™ä¸ªé¡¹ç›®åˆ°åº•æœ‰æ²¡æœ‰å¯ç”¨çš„å†å²æ–‡æœ¬
                    if not big.strip():
                        st.warning("è¯¥é¡¹ç›®ä¸‹æ²¡æœ‰å¯ç”¨çš„ç¿»è¯‘å†å²æ–‡æœ¬ï¼Œæ— æ³•æŠ½å–æœ¯è¯­ã€‚")
                        return

                    # è°ƒè¯•ç”¨:ä½ å¯ä»¥å…ˆçœ‹çœ‹é‡‡æ ·äº†å¤šå°‘å­—ã€å‰å‡ è¡Œæ˜¯ä»€ä¹ˆ
                    st.write({
                        "history_rows": len(rows),
                        "sample_chars": len(big),
                        "sample_preview": big[:300]
                    })

                    try:
                        res = ds_extract_terms(big, ak, model, src_lang="zh", tgt_lang="en", prefer_corpus_model=True)
                    except Exception as e:
                        st.error(f"è°ƒç”¨æœ¯è¯­æŠ½å–æ—¶å‡ºé”™: {e}")
                        return

                    # è°ƒè¯•ç”¨:å…ˆçœ‹ä¸€ä¸‹åŸå§‹ç»“æœé•¿ä»€ä¹ˆæ ·
                    st.write({"extract_result_preview": str(res)[:500]})
                    if not res:
                        st.info("æœªæŠ½å–åˆ°æœ¯è¯­æˆ–è§£æå¤±è´¥")
                    else:
                        st.success(f"æŠ½å–åˆ° {len(res)} æ¡.å‡†å¤‡æ‰¹é‡å†™å…¥â€¦â€¦")
                        ins = 0
                        for o in res:
                            cur.execute(
                                "INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example) VALUES (?, ?, ?, ?, ?, ?)",
                                (o["source_term"], o.get("target_term") or None, o.get("domain"), int(pid_ext), o.get("strategy"), o.get("example")),
                            )
                            ins += 1
                        conn.commit()
                        st.success(f"âœ… å·²å†™å…¥æœ¯è¯­åº“ {ins} æ¡")
                else:
                    st.warning("è¯·è¾“å…¥æ•°å­—å‹é¡¹ç›®ID")
        else:
            rid_ext = st.text_input("å†å²è®°å½•ID", key=sk5("ext_rid"))
            if st.button("å¼€å§‹æŠ½å–", key=sk5("ext_go_rec")):
                if rid_ext.isdigit():
                    row = cur.execute(
                        "SELECT src_path, output_text, project_id FROM trans_ext WHERE id=?",
                        (int(rid_ext),),
                    ).fetchone()
                    if not row:
                        st.warning("æœªæ‰¾åˆ°è¯¥è®°å½•")
                    else:
                        sp, ot, pid0 = row
                        src = read_source_file(sp) if sp else ""
                        big = (src + "\n" + (ot or "")).strip()
                        res = ds_extract_terms(big, ak, model, src_lang="zh", tgt_lang="en", prefer_corpus_model=True)
                        if not res:
                            st.info("æœªæŠ½å–åˆ°æœ¯è¯­æˆ–è§£æå¤±è´¥")
                        else:
                            st.success(f"æŠ½å–åˆ° {len(res)} æ¡.å‡†å¤‡æ‰¹é‡å†™å…¥â€¦â€¦")
                            ins = 0
                            for o in res:
                                cur.execute(
                                    "INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example) VALUES (?, ?, ?, ?, ?, ?)",
                                    (o["source_term"], o.get("target_term") or None, o.get("domain"), pid0, o.get("strategy"), o.get("example")),
                                )
                                ins += 1
                            conn.commit()
                            st.success(f"âœ… å·²å†™å…¥æœ¯è¯­åº“ {ins} æ¡(project_id={pid0})")

    # â€”â€” åˆ†ç±»ç®¡ç†
    with sub_tabs[6]:
        sk6 = lambda n: f"{key_prefix}_t6_{n}"
        st.markdown("#### åˆ†ç±»ç®¡ç†")
        c1, c2 = st.columns(2)
        with c1:
            ids_txt = st.text_area("æŒ‰ ID æ‰¹é‡è®¾ç½®åˆ†ç±»(é€—å·/ç©ºæ ¼/æ¢è¡Œåˆ†éš”)", key=sk6("cat_ids"))
            cat_to = st.text_input("è¦è®¾ç½®çš„åˆ†ç±»å", key=sk6("cat_name"))
            if st.button("æ‰¹é‡è®¾ç½®åˆ†ç±»", key=sk6("cat_set_ids")):
                import re
                raw = re.split(r"[,\s]+", (ids_txt or "").strip())
                ids = [int(x) for x in raw if x.isdigit()]
                if not ids or not cat_to.strip():
                    st.warning("è¯·å¡«å…¥IDåˆ—è¡¨ä¸åˆ†ç±»åç§°")
                else:
                    qmarks = ",".join(["?"] * len(ids))
                    cur.execute(f"UPDATE term_ext SET category=? WHERE id IN ({qmarks})", (cat_to.strip(), *ids))
                    conn.commit()
                    st.success(f"âœ… å·²è®¾ç½® {len(ids)} æ¡ä¸ºåˆ†ç±»:{cat_to.strip()}")

        with c2:
            pid_cat = st.text_input("å°†æŸé¡¹ç›®IDå…¨éƒ¨æœ¯è¯­è®¾ç½®ä¸ºåˆ†ç±»", key=sk6("cat_pid"))
            cat2_to = st.text_input("åˆ†ç±»å", key=sk6("cat2_name"))
            if st.button("æŒ‰é¡¹ç›®IDç»Ÿä¸€åˆ†ç±»", key=sk6("cat_set_pid")):
                if pid_cat.isdigit() and cat2_to.strip():
                    cur.execute("UPDATE term_ext SET category=? WHERE project_id=?", (cat2_to.strip(), int(pid_cat)))
                    conn.commit()
                    st.success(f"âœ… å·²å°†é¡¹ç›® {pid_cat} çš„æœ¯è¯­åˆ†ç±»è®¾ä¸º:{cat2_to.strip()}")
                else:
                    st.warning("è¯·å¡«å†™é¡¹ç›®IDä¸åˆ†ç±»å")

# ========== Session åˆå§‹åŒ– ==========
if "kb_embedder" not in st.session_state and KBEmbedder:
    st.session_state["kb_embedder"] = KBEmbedder(lazy=True)

# ========== é¡µé¢ç»“æ„ ==========
st.sidebar.title("å¯¼èˆª")

choice = st.sidebar.radio(
    "åŠŸèƒ½é€‰æ‹©",
    [
        "ğŸ“‚ ç¿»è¯‘é¡¹ç›®ç®¡ç†",
        "ğŸ“˜ æœ¯è¯­åº“ç®¡ç†",
        "ğŸ“Š ç¿»è¯‘å†å²",
        "ğŸ“š è¯­æ–™åº“ç®¡ç†",
        "ğŸ§  ç´¢å¼•ç®¡ç†",
    ],
)

st.title("ä¸ªäººç¿»è¯‘çŸ¥è¯†åº“ç®¡ç†ç³»ç»Ÿ3.0")


# ========== Tab1:ç¿»è¯‘é¡¹ç›®ç®¡ç† ==========
# ========== Tab1:ç¿»è¯‘é¡¹ç›®ç®¡ç† ==========
if choice.startswith("ğŸ“‚"):
    st.subheader("ç¿»è¯‘é¡¹ç›®ç®¡ç†")
    with st.form("new_project"):
        TAG_OPTIONS = ["æ”¿æ²»", "ç»æµ", "æ–‡åŒ–", "æ–‡ç‰©", "é‡‘è", "æ³•å¾‹"]
        SCENE_OPTIONS = ["å­¦æœ¯", "é…éŸ³ç¨¿", "æ­£å¼ä¼šè®®"]
        use_semantic = st.checkbox("åœ¨ç¿»è¯‘æ—¶å¯ç”¨è¯­ä¹‰å¬å›å‚è€ƒ", value=True)
        
        # === è¯­ä¹‰å¬å›èŒƒå›´é€‰æ‹© ===
        scope_label = "è¯­ä¹‰å¬å›èŒƒå›´"
        scope_options = {
            "ä»…å½“å‰é¡¹ç›®": "project",
            "åŒé¢†åŸŸ + å½“å‰é¡¹ç›®": "domain",
            "å…¨åº“": "all"
        }
        default_scope = "ä»…å½“å‰é¡¹ç›®"
        sel = st.selectbox(
            scope_label,
            list(scope_options.keys()),
            index=list(scope_options.keys()).index(default_scope),
            key="scope_sel_newproj"
        )
        st.session_state["scope_newproj"] = scope_options[sel]

        c1, c2 = st.columns([3, 2])
        with c1:
            title = st.text_input("é¡¹ç›®åç§°")
            tags_sel = st.multiselect("é¡¹ç›®æ ‡ç­¾(å¯å¤šé€‰)", TAG_OPTIONS)
            scene_sel = st.selectbox("åœºåˆ", SCENE_OPTIONS, index=0)
        with c2:
            translation_type = st.selectbox("ç¿»è¯‘æ–¹å¼", ["ä½¿ç”¨æœ¯è¯­åº“", "çº¯æœºå™¨ç¿»è¯‘"])
            translation_mode = st.radio("æ¨¡å¼", ["æ ‡å‡†æ¨¡å¼", "æœ¯è¯­çº¦æŸæ¨¡å¼"], horizontal=True)
            prompt_text = st.text_area(
                "ç¿»è¯‘æç¤º(æ³¨å…¥æ¨¡å‹ System Prompt)",
                placeholder="å†™ä¸‹å¯¹ DeepSeek çš„ç¡¬æ€§/ä¼˜å…ˆçº§æŒ‡ä»¤.å¦‚:æ—¶æ€ç»Ÿä¸€ä¸ºè¿‡å»å¼.ä¸“æœ‰åè¯ä¿æŒåŸæ–‡â€¦â€¦",
                height=120,
                key="new_proj_prompt"
            )
        # === é¢†åŸŸè‡ªåŠ¨ç»‘å®šé€»è¾‘ ===
        # è‹¥ç”¨æˆ·é€‰æ‹©äº†å¤šä¸ªæ ‡ç­¾.åˆ™é»˜è®¤ä»¥ç¬¬ä¸€ä¸ªæ ‡ç­¾ä¸ºé¢†åŸŸ
        domain_val = tags_sel[0] if tags_sel else None

        # === æäº¤æŒ‰é’® ===
        submitted = st.form_submit_button("ğŸ’¾ åˆ›å»ºé¡¹ç›®")
        if submitted:
            if not title:
                st.error("è¯·å¡«å†™é¡¹ç›®åç§°")
            else:
                try:
                    # ç¡®ä¿ items è¡¨å­˜åœ¨ domain å­—æ®µ
                    cur.execute("PRAGMA table_info(items);")
                    cols = [r[1] for r in cur.fetchall()]
                    if "domain" not in cols:
                        cur.execute("ALTER TABLE items ADD COLUMN domain TEXT;")
                        conn.commit()

                    # æ’å…¥æ–°é¡¹ç›®(å« domain)
                    cur.execute("""
                        INSERT INTO items(title, body, tags, domain,type)
                        VALUES (?, ?, ?, ?, 'project')
                    """, (
                        title,
                        prompt_text or "",
                        ",".join(tags_sel or []),
                        domain_val
                    ))
                    conn.commit()

                    st.success(f"âœ… é¡¹ç›® '{title}' å·²åˆ›å»º(é¢†åŸŸ:{domain_val or 'æœªæŒ‡å®š'})")
                except Exception as e:
                    st.error(f"âŒ åˆ›å»ºé¡¹ç›®å¤±è´¥: {e}")

    rows = cur.execute(
        """
        SELECT
            i.id,
            i.title,
            COALESCE(i.tags,'')              AS tags,
            COALESCE(MIN(e.src_path),'')     AS src_path,
            COALESCE(i.created_at,'')        AS created_at,
            COALESCE(i.scene,'')             AS scene,
            COALESCE(i.prompt,'')            AS prompt,
            COALESCE(i.mode,'')              AS mode,
            COALESCE(i.trans_type,'')        AS trans_type
        FROM items i
        LEFT JOIN item_ext e ON e.item_id = i.id
        WHERE COALESCE(i.type,'')='project'
        GROUP BY i.id
        ORDER BY i.id DESC
        """
    ).fetchall()

    if not rows:
        st.info("æš‚æ— é¡¹ç›®")
    else:
        # ç”¨äºæ”¶é›†æœ¬è½®å‹¾é€‰çš„é¡¹ç›®(ID + æ–‡ä»¶è·¯å¾„)
        batch_to_delete = []

        for pid, title, tags_str, path, ct, scene, prompt_ro, mode, trans_type in rows:
            ensure_legacy_file_record(cur, conn, pid, path or None)
            file_records = fetch_project_files(cur, pid)
            tag_display = tags_str or "æ— "
            file_display = f"{len(file_records)} ä¸ªæ–‡ä»¶" if file_records else "æ— "
            selected_src_path = None

            with st.expander(f"{title}ï½œæ–¹å¼:{mode or 'æœªè®¾'}ï½œæ ‡ç­¾:{tag_display}ï½œåœºåˆ:{scene or 'æœªå¡«'}ï½œæ–‡ä»¶:{file_display}ï½œåˆ›å»º:{ct}"):
                # âœ… æ‰¹é‡æ“ä½œç”¨çš„å‹¾é€‰æ¡†
                sel = st.checkbox("é€‰æ‹©æ­¤é¡¹ç›®(ç”¨äºæ‰¹é‡åˆ é™¤)", key=f"sel_proj_{pid}")
                if sel:
                    batch_to_delete.append(pid)

                c1, c2, c3 = st.columns([2, 2, 1])
                with c1:
                    st.selectbox("ç¿»è¯‘æ–¹å‘", ["ä¸­è¯‘è‹±", "è‹±è¯‘ä¸­"], key=f"lang_{pid}")
                with c2:
                    max_len = st.number_input("åˆ†å—é•¿åº¦", 600, 2000, 1200, 100, key=f"len_{pid}")
                with c3:
                    use_terms = st.checkbox("ä½¿ç”¨æœ¯è¯­åº“", value=(mode == "æœ¯è¯­çº¦æŸæ¨¡å¼"), key=f"ut_{pid}")

                st.caption(f"æ ‡ç­¾:{tag_display}")
                st.caption(f"åœºåˆ:{scene or 'æœªå¡«å†™'}")
             
                # === é¢†åŸŸ(domain)è®¾ç½®:è·Ÿéšç¬¬ä¸€ä¸ªæ ‡ç­¾ æˆ– æ‰‹åŠ¨é€‰æ‹© ===
                # è¯»å–å½“å‰é¡¹ç›®çš„ domain / tags
                # ä¿åº•:items è¡¨è‹¥æ²¡æœ‰ domain åˆ—.åŠ¨æ€è¡¥åˆ—(å…¼å®¹æ—§åº“)
                cols_items = [r[1] for r in cur.execute("PRAGMA table_info(items)").fetchall()]
                if "domain" not in cols_items:
                    try:
                        cur.execute("ALTER TABLE items ADD COLUMN domain TEXT;")
                        conn.commit()
                    except Exception:
                        pass  # å¹¶å‘æˆ–å·²æœ‰åˆ—æ—¶å¿½ç•¥
 
                row = cur.execute(
                    "SELECT IFNULL(domain,''), IFNULL(tags,'') FROM items WHERE id=?",
                    (pid,)
                ).fetchone()
                domain0, tags0 = (row or ["", ""])
                tags_list = [t for t in (tags0.split(",") if tags0 else []) if t]

                DOMAIN_OPTIONS = ["æ”¿æ²»", "ç»æµ", "æ–‡åŒ–", "æ–‡ç‰©", "é‡‘è", "æ³•å¾‹"]

                dom_mode = st.radio(
                    "é¢†åŸŸè®¾ç½®æ–¹å¼",
                    ["è·Ÿéšç¬¬ä¸€ä¸ªæ ‡ç­¾", "æ‰‹åŠ¨é€‰æ‹©"],
                    horizontal=True,
                    key=f"dom_mode_{pid}"
                )

                if dom_mode == "è·Ÿéšç¬¬ä¸€ä¸ªæ ‡ç­¾":
                    domain_val = (tags_list[0] if tags_list else (domain0 or None))
                    st.caption(f"å½“å‰é¢†åŸŸ(è‡ªåŠ¨):{domain_val or 'æœªæŒ‡å®š'}(ç”±ç¬¬ä¸€ä¸ªæ ‡ç­¾å†³å®š)")
                else:
                    idx = DOMAIN_OPTIONS.index(domain0) if domain0 in DOMAIN_OPTIONS else 0
                    domain_val = st.selectbox(
                        "é¢†åŸŸ(æ‰‹åŠ¨é€‰æ‹©)",
                        DOMAIN_OPTIONS,
                        index=idx,
                        key=f"dom_sel_{pid}"
                    )

                sync_corpus = st.checkbox(
                    "åŒæ—¶å›å¡«è¯¥é¡¹ç›®ä¸‹è¯­æ–™çš„é¢†åŸŸ(ä»…è¡¥ç©ºæˆ–åŸé¢†åŸŸç›¸åŒæ—¶è¦†ç›–)",
                    value=True,
                    key=f"sync_corpus_{pid}"
                )

                if st.button("ğŸ’¾ ä¿å­˜é¢†åŸŸè®¾ç½®", key=f"save_dom_{pid}", type="secondary"):
                    try:
                        # ç¡®ä¿ items.domain å­˜åœ¨
                        cols_items = [r[1] for r in cur.execute("PRAGMA table_info(items)").fetchall()]
                        if "domain" not in cols_items:
                            cur.execute("ALTER TABLE items ADD COLUMN domain TEXT;")
                            conn.commit()

                        # æ›´æ–° items.domain
                        cur.execute("UPDATE items SET domain=? WHERE id=?", (domain_val, pid))
                        conn.commit()

                        # åŒæ­¥è¯­æ–™åº“çš„ domain(ä¼˜å…ˆ corpus_main.é€€å› corpus)
                        def _table_exists(tb: str) -> bool:
                            return bool(cur.execute(
                                "SELECT name FROM sqlite_master WHERE type='table' AND name=?;", (tb,)
                            ).fetchone())

                        corpus_tb = "corpus_main" if _table_exists("corpus_main") else ("corpus" if _table_exists("corpus") else None)
                        if sync_corpus and corpus_tb and domain_val:
                            # ç¡®ä¿åˆ—å­˜åœ¨
                            cols_corpus = [r[1] for r in cur.execute(f"PRAGMA table_info({corpus_tb})").fetchall()]
                            if "domain" not in cols_corpus:
                                cur.execute(f"ALTER TABLE {corpus_tb} ADD COLUMN domain TEXT;")
                                conn.commit()

                            # ä»…è¡¥ç©ºæˆ–åŸ domain ä¸ domain0 ç›¸åŒæ—¶è¦†ç›–.é¿å…è¯¯ä¼¤è·¨é¢†åŸŸæ•°æ®
                            cur.execute(f"""
                                UPDATE {corpus_tb}
                                SET domain = ?
                                WHERE project_id = ?
                                AND (domain IS NULL OR TRIM(domain)='' OR domain = ?)
                            """, (domain_val, pid, domain0 or ""))
                            conn.commit()

                        st.success("âœ… å·²ä¿å­˜é¢†åŸŸè®¾ç½®")
                        st.rerun()

                    except Exception as e:
                        st.error(f"âŒ ä¿å­˜å¤±è´¥:{e}")

                if prompt_ro:
                    try:
                        cur.execute("SELECT IFNULL(prompt, '') FROM items WHERE id=?", (pid,))
                        prompt_ro = (cur.fetchone() or [""])[0]
                    except Exception:
                        prompt_ro = ""

                    st.text_area("ç¿»è¯‘æç¤º(åªè¯»)", prompt_ro or "", height=120, key=f"proj_prompt_ro_{pid}")

                file_col, action_col = st.columns([3, 1])

                with file_col:
                    if file_records:
                        option_labels = []
                        option_map = {}
                        for rec in file_records:
                            label = f"[#{rec['id']}] {rec['name']}"
                            if rec["uploaded_at"]:
                                label += f"ï½œ{rec['uploaded_at']}"
                            option_labels.append(label)
                            option_map[label] = rec
                        sel_key = f"file_sel_{pid}"
                        default_label = st.session_state.get(sel_key)
                        if default_label not in option_labels:
                            default_label = option_labels[0]
                            st.session_state[sel_key] = default_label
                        chosen_label = st.selectbox(
                            "é€‰æ‹©è¦ç¿»è¯‘çš„æºæ–‡ä»¶",
                            option_labels,
                            index=option_labels.index(default_label),
                            key=sel_key,
                        )
                        selected_src_path = option_map[chosen_label]["path"]
                        st.caption(f"å·²ä¸Šä¼  {len(file_records)} ä¸ªé™„ä»¶ï¼Œå½“å‰é€‰ä¸­:{option_map[chosen_label]['name']}")
                    else:
                        selected_src_path = path or None
                        st.info("å°šæœªä¸Šä¼ æºæ–‡ä»¶ï¼Œå¯åœ¨ä¸‹æ–¹ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶ã€‚")                      

                    upload_key = f"up_multi_{pid}"
                    processed_key = f"up_multi_processed_{pid}"
                    if upload_key not in st.session_state:
                        st.session_state[processed_key] = set()
                    uploads = st.file_uploader(
                        "æ–°å¢/è¡¥ä¼ æ–‡ä»¶(å¯å¤šé€‰)",
                        type=["txt", "docx", "xlsx", "pdf"],
                        accept_multiple_files=True,
                        key=upload_key
                    )
                    if uploads:
                        processed_names = st.session_state.setdefault(processed_key, set())
                        saved = 0
                        for uf in uploads:
                            if not uf or uf.name in processed_names:
                                continue
                            data = uf.read()
                            new_path = register_project_file(cur, conn, pid, uf.name, data)
                            if new_path:
                                cur.execute("SELECT id FROM item_ext WHERE item_id=?", (pid,))
                                r = cur.fetchone()
                                if r:
                                    cur.execute("UPDATE item_ext SET src_path=? WHERE id=?", (new_path, r[0]))
                                else:
                                    cur.execute("INSERT INTO item_ext (item_id, src_path) VALUES (?, ?)", (pid, new_path))
                                conn.commit()
                                saved += 1
                                processed_names.add(uf.name)
                        if saved:
                            st.success(f"âœ… å·²ä¸Šä¼  {saved} ä¸ªæ–‡ä»¶")
                    else:
                        st.session_state.pop(processed_key, None)

                    if file_records:
                        st.markdown("é™„ä»¶åˆ—è¡¨:")
                        for rec in file_records:
                            info_cols = st.columns([5, 1])
                            info = f"[#{rec['id']}] {rec['name']}ï½œ{os.path.basename(rec['path'])}"
                            if rec["uploaded_at"]:
                                info += f"ï½œ{rec['uploaded_at']}"
                            info_cols[0].write(info)
                            if info_cols[1].button("åˆ é™¤", key=f"del_file_{rec['id']}"):
                                remove_project_file(cur, conn, rec["id"])
                                st.rerun()

                with action_col:
                    if st.button("åˆ é™¤é¡¹ç›®", key=f"del_proj_{pid}"):
                        cleanup_project_files(cur, conn, pid)
                        cur.execute("DELETE FROM items WHERE id=?", (pid,))
                        cur.execute("DELETE FROM item_ext WHERE item_id=?", (pid,))
                        conn.commit()
                        st.success("é¡¹ç›®å·²åˆ é™¤")
                        st.rerun()

                # â€”â€” æ‰§è¡Œç¿»è¯‘
                if st.button("æ‰§è¡Œç¿»è¯‘", key=f"run_{pid}", type="primary"):
                    run_project_translation_ui(
                        pid=pid,
                        project_title=title,
                        src_path=selected_src_path,
                        conn=conn,
                        cur=cur
                    )

                # â€”â€” æ–°å¢ï¼šè¿›å…¥ç¿»è¯‘å·¥ä½œå°ï¼ˆå¯ç¼–è¾‘ï¼‰
                if st.button("è¿›å…¥ç¿»è¯‘å·¥ä½œå°ï¼ˆå¯ç¼–è¾‘ï¼‰", key=f"workspace_{pid}", type="secondary"):
                    # 1) ç¯å¢ƒæ£€æŸ¥ï¼šæœ‰æºæ–‡ä»¶å—ï¼Ÿ
                    if not selected_src_path or not os.path.exists(selected_src_path):
                        st.error("ç¼ºå°‘æºæ–‡ä»¶ï¼Œè¯·å…ˆåœ¨ä¸Šé¢é€‰æ‹©æˆ–ä¸Šä¼ æºæ–‡ä»¶ã€‚")
                        st.stop()
                    st.session_state[f"workspace_activated_{pid}"] = True

                    # 2) è¯»å–æºæ–‡æœ¬ï¼ˆè¿™é‡Œå®šä¹‰ src_textï¼‰
                    src_text = read_source_file(selected_src_path)

                    # 3) åˆ†æ®µ
                    blocks = split_paragraphs(src_text)
                    if not blocks:
                        st.error("æºæ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œæˆ–æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ®µè½")
                        st.stop()

                    # 4) æœ¯è¯­ï¼šç”¨ç»Ÿä¸€æ¥å£ + è½¬æˆ term_pairs ä¾›é«˜äº®ç”¨
                    term_map_all, term_meta = get_terms_for_project(cur, pid, use_dynamic=True)
                    term_pairs = list(term_map_all.items())

                    # 5) ç”¨ç»Ÿä¸€ç®¡çº¿ translate_block_with_kb åšåˆè¯‘
                    ak, model = get_deepseek()
                    if not ak:
                        st.error("æœªæ£€æµ‹åˆ° DeepSeek Keyï¼Œè¯·é…ç½® deepseek")
                        st.stop()

                    # ç¿»è¯‘æ–¹å‘ï¼ˆæ²¿ç”¨ä½ é¡¹ç›®é‡Œå·²æœ‰çš„å˜é‡ï¼‰
                    lang_pair_val = st.session_state.get(f"lang_{pid}", "ä¸­è¯‘è‹±")

                    # æ˜¯å¦å¯ç”¨è¯­ä¹‰å¬å› / å¬å›èŒƒå›´ï¼Œç›´æ¥æ²¿ç”¨ä¸Šé¢ Tab1 çš„è®¾ç½®
                    use_semantic_val = use_semantic
                    scope_val_local = scope_label

                    draft = []
                    for blk in blocks:
                        blk = (blk or "").strip()
                        if not blk:
                            draft.append("")
                            continue

                        res = translate_block_with_kb(
                            cur=cur,
                            project_id=pid,
                            block_text=blk,
                            lang_pair=lang_pair_val,
                            ak=ak,
                            model=model,
                            use_semantic=use_semantic_val,
                            scope=scope_val_local,
                            fewshot_examples=None,  # å·¥ä½œå°æ¨¡å¼å…ˆä¸æ³¨å…¥ few-shot
                        )
                        draft.append(res["tgt"])

                    # 6) ä¿å­˜åˆ° session_stateï¼Œä¾›ä¸‹é¢ç¼–è¾‘ç•Œé¢ä½¿ç”¨
                    st.session_state[f"workspace_src_{pid}"] = blocks
                    st.session_state[f"workspace_draft_{pid}"] = draft
                    st.session_state[f"workspace_terms_{pid}"] = term_pairs

                    st.success("è‰ç¨¿å·²ç”Ÿæˆï¼Œè¯·ä¸‹æ–¹å¼€å§‹ç¼–è¾‘ â†“")


                # â‘¢ ç¿»è¯‘å·¥ä½œå° UIï¼šåªæœ‰å½“ session é‡Œæœ‰è‰ç¨¿æ—¶æ‰æ˜¾ç¤º
                if st.session_state.get(f"workspace_draft_{pid}") and st.session_state.get(f"workspace_activated_{pid}", False):

                    st.markdown("## ğŸ“ ç¿»è¯‘å·¥ä½œå°ï¼ˆå¯ç¼–è¾‘ï¼‰")

                    # ä» session ä¸­å–å›è‰ç¨¿å’Œæœ¯è¯­
                    blocks = st.session_state.get(f"workspace_src_{pid}", [])
                    draft  = st.session_state.get(f"workspace_draft_{pid}", [])
                    terms  = st.session_state.get(f"workspace_terms_{pid}", [])

                    if not blocks or not draft:
                        st.info("å½“å‰æš‚æ— è‰ç¨¿ï¼Œè¯·å…ˆç‚¹å‡»â€œè¿›å…¥ç¿»è¯‘å·¥ä½œå°ï¼ˆå¯ç¼–è¾‘ï¼‰â€ç”Ÿæˆåˆç¨¿ã€‚")
                    else:
                        edited_blocks = []

                        for i, (src, trg) in enumerate(zip(blocks, draft), 1):
                            st.markdown(f"### æ®µè½ {i}")

                            col1, col2 = st.columns(2)

                            with col1:
                                st.markdown("**åŸæ–‡**")
                                st.markdown(
                                    f"<div style='padding:8px;border:1px solid #ccc;background:#f8f8f8'>{src}</div>",
                                    unsafe_allow_html=True
                                )

                            with col2:
                                st.markdown("**è¯‘æ–‡ï¼ˆå¯ç¼–è¾‘ï¼‰**")
                                new_trg = st.text_area(
                                    label="ç¼–è¾‘åçš„è¯‘æ–‡",
                                    value=trg,
                                    key=f"edit_{pid}_{i}",
                                    height=120
                                )
                                edited_blocks.append(new_trg)

                                # æœ¯è¯­é«˜äº®ï¼ˆå¦‚æœä½ å‰é¢å·²ç»å®šä¹‰äº† highlight_termsï¼‰
                                if "highlight_terms" in globals():
                                    highlighted = highlight_terms(new_trg, terms)
                                    st.markdown("æœ¯è¯­é«˜äº®ï¼š")
                                    st.markdown(
                                        f"<div style='padding:8px;border:1px solid #ccc;background:#f0fff0'>{highlighted}</div>",
                                        unsafe_allow_html=True
                                    )

                        # â€”â€” ç¡®è®¤ç”Ÿæˆæœ€ç»ˆè¯‘æ–‡ â€”â€” 
                        if st.button("âœ… ç¡®è®¤ç”Ÿæˆæœ€ç»ˆè¯‘æ–‡", key=f"confirm_{pid}", type="primary"):
                            final_text = "\n\n".join(edited_blocks)

                            # è¯­è¨€æ–¹å‘ä» session é‡Œæ‹¿ï¼ˆè·Ÿä½ ç¿»è¯‘æ—¶ä¿æŒä¸€è‡´ï¼‰
                            lang_pair_val = st.session_state.get(f"lang_{pid}", "ä¸­è¯‘è‹±")

                            cur.execute("""
                                INSERT INTO trans_ext (project_id, src_path, lang_pair, mode, output_text, created_at)
                                VALUES (?, ?, ?, ?, ?, datetime('now'))
                            """, (pid, selected_src_path, lang_pair_val, "å·¥ä½œå°æ¨¡å¼", final_text))
                            conn.commit()

                            st.success("æœ€ç»ˆè¯‘æ–‡å·²ç”Ÿæˆå¹¶å†™å…¥å†å²ï¼")

                            # æ¸…ç©ºå·¥ä½œå°è‰ç¨¿
                            st.session_state.pop(f"workspace_src_{pid}", None)
                            st.session_state.pop(f"workspace_draft_{pid}", None)
                            st.session_state.pop(f"workspace_terms_{pid}", None)
 
        # â€”â€” æ‰¹é‡åˆ é™¤æŒ‰é’®(åœ¨é¡¹ç›®åˆ—è¡¨åº•éƒ¨)
        if batch_to_delete:
            st.warning(f"å·²å‹¾é€‰ {len(batch_to_delete)} ä¸ªé¡¹ç›®ï¼Œæ“ä½œä¸å¯æ’¤é”€ã€‚")
            if st.button("ğŸ—‘ï¸ æ‰¹é‡åˆ é™¤é€‰ä¸­é¡¹ç›®", key="batch_del_projects"):
                deleted = 0
                for pid_del in batch_to_delete:
                    cleanup_project_files(cur, conn, pid_del)
                    cur.execute("DELETE FROM items WHERE id=?", (pid_del,))
                    cur.execute("DELETE FROM item_ext WHERE item_id=?", (pid_del,))
                    deleted += 1
                conn.commit()
                st.success(f"å·²æ‰¹é‡åˆ é™¤ {deleted} ä¸ªé¡¹ç›®")
                st.rerun()
        else:
            st.caption("æç¤º:å¦‚éœ€æ‰¹é‡åˆ é™¤ï¼Œå¯åœ¨ä¸Šæ–¹å‹¾é€‰å¤šä¸ªé¡¹ç›®ã€‚")

# ========== Tab2:æœ¯è¯­åº“ç®¡ç† ==========
elif choice.startswith("ğŸ“˜"):
    render_term_management(st, cur, conn, BASE_DIR, key_prefix="term")


# ========== Tab3:ç¿»è¯‘å†å²(å¢å¼ºç‰ˆ) ==========
elif choice.startswith("ğŸ“Š"):
    st.subheader("ğŸ“Š ç¿»è¯‘å†å²è®°å½•(å¯å†™å…¥è¯­æ–™ / æŠ½å–æœ¯è¯­ / ä¸‹è½½å¯¹ç…§ / åˆ é™¤)")

    rows = cur.execute("""
        SELECT id, project_id, lang_pair,
               substr(IFNULL(output_text,''),1,120) AS prev, created_at
        FROM trans_ext
        ORDER BY datetime(created_at) DESC
        LIMIT 200
    """).fetchall()

    if not rows:
        st.info("æš‚æ— å†å²è®°å½•ã€‚")
    else:
        for rid, pid, lp, prev, ts in rows:
            # é¡¹ç›®æ ‡é¢˜(åšè¯­æ–™æ ‡é¢˜/å±•ç¤º)
            ttl_row = cur.execute("SELECT IFNULL(title,'') FROM items WHERE id=?", (pid,)).fetchone()
            proj_title = (ttl_row or [""])[0] or f"project#{pid}"
            proj_domain = _project_domain(pid, cur)

            with st.expander(f"#{rid}ï½œé¡¹ç›® {pid}ï½œ{proj_title}ï½œ{lp}ï½œ{ts}", expanded=False):
                # è¯‘æ–‡å…¨æ–‡ & æºæ–‡ä»¶è·¯å¾„
                det = cur.execute("SELECT output_text, src_path FROM trans_ext WHERE id=?", (rid,)).fetchone()
                tgt_full, src_path = det or ("", "")
                st.code(prev or "", language="text")
                st.text_area("è¯‘æ–‡å…¨æ–‡", tgt_full or "", height=220, key=f"hist_full_{rid}")

                # å°è¯•è¯»å–åŸæ–‡(å¦‚æœå½“æ—¶ä¿å­˜äº†æºæ–‡ä»¶è·¯å¾„)
                try:
                    src_full = read_source_file(src_path) if src_path else ""
                except Exception:
                    src_full = ""

                with st.expander("åŸæ–‡é¢„è§ˆ(è‹¥ä¸Šä¼ äº†æºæ–‡ä»¶)", expanded=False):
                    st.text_area("åŸæ–‡å…¨æ–‡", src_full or "(æœªä¿å­˜/æœªä¸Šä¼ æºæ–‡ä»¶)", height=160, key=f"hist_src_{rid}")

                c1, c2, c3, c4, c5 = st.columns(5)

                # 1) æ·»åŠ è¿›è¯­æ–™åº“ / æ·»åŠ +é‡å»ºç´¢å¼•
                with c1:
                    # 1-1 åªå†™å…¥è¯­æ–™åº“
                    if st.button("â• æ·»åŠ è¿›è¯­æ–™åº“", key=f"hist_add_corpus_{rid}"):
                        if not src_full and not tgt_full:
                            st.warning("åŸæ–‡å’Œè¯‘æ–‡éƒ½ä¸ºç©ºï¼Œæ— æ³•å†™å…¥è¯­æ–™åº“ã€‚")
                        else:
                            cur.execute("""
                                INSERT INTO corpus (title, project_id, lang_pair, src_text, tgt_text, note, created_at)
                                VALUES (?, ?, ?, ?, ?, ?, datetime('now'))
                            """, (
                                f"{proj_title} Â· history#{rid}",
                                pid,
                                lp or "",
                                src_full or None,
                                tgt_full or "",
                                f"from trans_ext#{rid}",
                            ))
                            conn.commit()
                            st.success("âœ… å·²å†™å…¥è¯­æ–™åº“")

                    # 1-2 å†™å…¥è¯­æ–™åº“å¹¶é‡å»ºç´¢å¼•
                    if st.button("â• æ·»åŠ å¹¶é‡å»ºç´¢å¼•", key=f"hist_add_corpus_rebuild_{rid}_{idx}"):
                        if not src_full and not tgt_full:
                            st.warning("åŸæ–‡å’Œè¯‘æ–‡éƒ½ä¸ºç©ºï¼Œæ— æ³•å†™å…¥è¯­æ–™åº“ã€‚")
                        else:
                            # å…ˆå†™å…¥è¯­æ–™åº“
                            cur.execute("""
                                INSERT INTO corpus (title, project_id, lang_pair, src_text, tgt_text, note, created_at)
                                VALUES (?, ?, ?, ?, ?, ?, datetime('now'))
                            """, (
                                f"{proj_title} Â· history#{rid}",
                                pid,
                                lp or "",
                                src_full or None,
                                tgt_full or "",
                                f"from trans_ext#{rid}",
                            ))
                            conn.commit()

                            # å†é‡å»ºè¯¥é¡¹ç›®çš„è¯­ä¹‰ç´¢å¼•
                            res_idx = rebuild_project_semantic_index(cur, pid, split_fn=_split_pair_for_index)
                            if res_idx.get("ok"):
                                st.success(
                                    f"âœ… å·²å†™å…¥è¯­æ–™åº“å¹¶é‡å»ºç´¢å¼•: æ–°å¢ {res_idx['added']} æ¡, æ€»é‡ {res_idx['total']} æ¡"
                                )
                            else:
                                st.warning(
                                    f"å·²å†™å…¥è¯­æ–™åº“ï¼Œä½†é‡å»ºç´¢å¼•å¤±è´¥: {res_idx.get('msg','æœªçŸ¥é”™è¯¯')}"
                                )

                # 2) æå–æœ¯è¯­(ä¼˜å…ˆè¯­æ–™åº“åŒæ¬¾æ¨¡å‹ï¼Œç¼ºçœå›é€€ DeepSeek)
                with c2:
                    if st.button("ğŸ§  æå–æœ¯è¯­", key=f"hist_extract_terms_{rid}"):
                        ak, model = get_deepseek()
                        if not ak:
                            st.info("æœªæ£€æµ‹åˆ° DeepSeek Keyï¼Œå°†ä»…ä½¿ç”¨è¯­æ–™åº“åŒæ¬¾æ¨¡å‹è¿›è¡ŒæŠ½å–ã€‚")

                        # åˆå¹¶åŸæ–‡+è¯‘æ–‡.æé«˜å€™é€‰è´¨é‡
                        big = ((src_full or "") + "\n" + (tgt_full or "")).strip()
                        res = ds_extract_terms(
                            big,
                            ak,
                            model,
                            src_lang="zh",
                            tgt_lang="en",
                            prefer_corpus_model=True,
                            default_domain=proj_domain,
                        )
                        res, dup_terms = dedup_terms_against_db(cur, res, pid)
                        if not res:
                            st.info("æœªæŠ½å–åˆ°æœ¯è¯­æˆ–è§£æå¤±è´¥")
                        else:
                            ins_term = ins_corpus = 0
                            for o in res:
                                domain_val = (o.get("domain") or proj_domain or "å…¶ä»–")
                                strategy_val = (o.get("strategy") or "history-extract")
                                cur.execute("""
                                    INSERT INTO term_ext (source_term, target_term, domain, project_id, strategy, example)
                                    VALUES (?, ?, ?, ?, ?, ?)
                                """, (
                                    o.get("source_term") or "",
                                    (o.get("target_term") or None),
                                    domain_val,
                                    pid,
                                    strategy_val,
                                    (o.get("example") or None),
                                ))
                                ins_term += 1

                                src_ex, tgt_ex = _locate_example_pair(o.get("example"), src_full, tgt_full)
                                if src_ex:
                                    cur.execute(
                                        """
                                        INSERT INTO corpus(title, project_id, lang_pair, src_text, tgt_text, note, domain, source, created_at)
                                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
                                        """,
                                        (
                                            f"{proj_title} Â· term#{rid}",
                                            pid,
                                            lp or "",
                                            src_ex,
                                            tgt_ex,
                                            "term-example",
                                            domain_val,
                                            "history-term",
                                        ),
                                    )
                                    ins_corpus += 1
                            conn.commit()
                            msg = f"âœ… å·²å†™å…¥æœ¯è¯­åº“ {ins_term} æ¡ï¼ŒåŒæ­¥è¯­æ–™åº“ {ins_corpus} æ¡"
                            if dup_terms:
                                msg += f"ï¼›è·³è¿‡é‡å¤ {len(dup_terms)} æ¡"
                            st.success(msg)

                # 3) ä¸‹è½½åŒè¯­å¯¹ç…§(CSV / DOCX)
                with c3:
                    if st.button("â¬‡ï¸ CSV å¯¹ç…§", key=f"hist_dl_bicsv_btn_{rid}"):
                        if not src_full:
                            st.warning("æ‰¾ä¸åˆ°åŸæ–‡(æœªä¸Šä¼ æºæ–‡ä»¶).æ— æ³•ç”Ÿæˆ CSV å¯¹ç…§")
                        else:
                            try:
                                csv_name = f"bilingual_history_{rid}.csv"
                                csv_bytes = export_csv_bilingual((src_full, tgt_full),
                                    filename=f"bilingual_history_{rid}.csv"
                                )
                            except TypeError:
                                # å¦‚æœä½ çš„å¯¼å‡ºå‡½æ•°æ˜¯ textâ†’bytes ç‰ˆæœ¬
                                csv_name = f"bilingual_history_{rid}.csv"
                                csv_bytes = export_csv_bilingual(src_full, tgt_full)
                            st.download_button("ä¸‹è½½ CSV", data=csv_bytes,
                                               file_name=csv_name, mime="text/csv",
                                               key=f"hist_dl_bicsv_{rid}")

                with c4:
                    if st.button("â¬‡ï¸ DOCX å¯¹ç…§", key=f"hist_dl_bidocx_btn_{rid}"):
                        if not src_full:
                            st.warning("æ‰¾ä¸åˆ°åŸæ–‡(æœªä¸Šä¼ æºæ–‡ä»¶).æ— æ³•ç”Ÿæˆ DOCX å¯¹ç…§")
                        else:
                            try:
                                docx_path = export_docx_bilingual(
                                    filename=f"bilingual_history_{rid}.docx"
                                )
                                with open(docx_path, "rb") as f:
                                    data_docx = f.read()
                            except TypeError:
                                # å¦‚æœä½ çš„å¯¼å‡ºå‡½æ•°æ˜¯ textâ†’bytes ç‰ˆæœ¬
                                data_docx = export_docx_bilingual(src_full, tgt_full)
                            st.download_button("ä¸‹è½½ DOCX", data=data_docx,
                                               file_name=f"bilingual_history_{rid}.docx",
                                               mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                               key=f"hist_dl_bidocx_{rid}")

                # 4) ğŸ—‘ åˆ é™¤æœ¬æ¡å†å²(å®‰å…¨ç¡®è®¤)
                with c5:
                    with st.expander("ğŸ—‘ åˆ é™¤æœ¬æ¡å†å²(ä¸å¯æ¢å¤)", expanded=False):
                        st.warning("æ­¤æ“ä½œå°†æ°¸ä¹…åˆ é™¤è¯¥æ¡ trans_ext è®°å½•(ä¸å½±å“å·²å†™å…¥è¯­æ–™åº“/æœ¯è¯­è¡¨çš„æ•°æ®)ã€‚")
                        ok = st.checkbox(f"æˆ‘ç¡®è®¤åˆ é™¤ #{rid}", key=f"hist_del_ck_{rid}")
                        if st.button("ç¡®è®¤åˆ é™¤", key=f"hist_del_btn_{rid}") and ok:
                            cur.execute("DELETE FROM trans_ext WHERE id=?", (rid,))
                            conn.commit()
                            st.success("å·²åˆ é™¤.è¯·åˆ·æ–°é¡µé¢æŸ¥çœ‹ç»“æœã€‚")
                            st.stop()  # ç»ˆæ­¢æœ¬æ¬¡æ¸²æŸ“.é¿å…åœ¨å·²åˆ é™¤æ•°æ®ä¸Šç»§ç»­æ“ä½œ

                # åŸæœ‰çš„â€œä¸‹è½½è¯‘æ–‡ TXTâ€
                st.download_button("ä¸‹è½½è¯‘æ–‡ (TXT)", tgt_full or "",
                                   file_name=f"history_{rid}.txt",
                                   mime="text/plain",
                                   key=f"hist_dl_txt_{rid}")

# ========== Tab4:è¯­æ–™åº“ç®¡ç† ==========
elif choice.startswith("ğŸ“š"):
    def render_corpus_manager(st, cur, conn, pid_prefix="corpus"):
        st.header("ğŸ“š è¯­æ–™åº“ç®¡ç†")
        sk = make_sk(pid_prefix)

    render_corpus_manager(st, cur, conn)

    # åˆå§‹åŒ– Few-shot çŠ¶æ€å­—å…¸
    get_project_ref_ids(None)
    get_project_fewshot_enabled(None)
    st.session_state.setdefault("corpus_target_project", None)
    st.session_state.setdefault("corpus_target_label", "(è¯·é€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®)")

    sub = st.tabs(["æ–°å»ºè¯­æ–™", "æµè§ˆ/æ£€ç´¢", "ä½¿ç”¨ä¸å¯¼å‡º"])

    # -------- æ–°å»ºè¯­æ–™ --------
    with sub[0]:
        st.subheader("ğŸ“¥ ä¸Šä¼  / å¯¹é½ / å…¥åº“")

        colA, colB = st.columns(2)
        with colA:
            one_file = st.file_uploader("â‘  å•ä¸ªæ–‡ä»¶(DOCX è¡¨æ ¼å¯¹ç…§ / å•è¯­ DOCX/TXT/PDF)",
                                        type=["docx", "txt", "pdf"], key="up_one")
        with colB:
            two_src = st.file_uploader("â‘¡ åŸæ–‡æ–‡ä»¶(å¯é€‰:ä¸ â‘¢ æ­é…åšå¯¹é½)",
                                       type=["docx", "txt", "csv", "pdf"], key="up_src")
            two_tgt = st.file_uploader("â‘¢ è¯‘æ–‡æ–‡ä»¶(å¯é€‰:ä¸ â‘¡ æ­é…åšå¯¹é½)",
                                       type=["docx", "txt", "csv", "pdf"], key="up_tgt")

        st.divider()
        meta1, meta2, meta3 = st.columns([2, 1, 1])
        with meta1:
            title = st.text_input("è¯­æ–™æ ‡é¢˜", value="æœªå‘½åè¯­æ–™")
        with meta2:
            lp = st.selectbox("æ–¹å‘", ["è‡ªåŠ¨", "ä¸­è¯‘è‹±", "è‹±è¯‘ä¸­"])
        with meta3:
            pid_val = st.text_input("é¡¹ç›®ID(å¯ç•™ç©º)")
        pid = int(pid_val) if pid_val.strip().isdigit() else None

        ins = 0
        pairs = []
        src_text = tgt_text = ""
        preview_df = None

        # ========== è·¯å¾„ A:å•ä¸ªæ–‡ä»¶ ==========
        if one_file is not None and (two_src is None and two_tgt is None):
            ext = (one_file.name.split(".")[-1] or "").lower()
            bio = io.BytesIO(one_file.getvalue())

            if ext == "docx":
                # å…ˆå°è¯•â€œè¡¨æ ¼å¯¹ç…§â€
                tables = read_docx_tables_info(io.BytesIO(bio.getvalue()))
                if tables:
                    st.caption("æ£€æµ‹åˆ° DOCX è¡¨æ ¼ï¼Œä¼˜å…ˆä½œä¸ºåŒè¯­å¯¹ç…§å¯¼å…¥ã€‚")
                    # ç®€å•èµ·è§ï¼Œé»˜è®¤ç¬¬ 0 å¼ è¡¨çš„ç¬¬ 0/1 åˆ—;ä½ ä¹Ÿå¯ä»¥åŠ å…¥ä¸‹æ‹‰é€‰æ‹©
                    pairs = extract_pairs_from_docx_table(
                        io.BytesIO(bio.getvalue()),
                        table_index=0,
                        src_col=0,
                        tgt_col=1
                    )
                else:
                    # æ²¡æœ‰è¡¨æ ¼ â†’ å•è¯­æ–‡æœ¬
                    src_text = read_docx_text(io.BytesIO(bio.getvalue()))

            elif ext == "txt":
                src_text = read_txt(bio)

            elif ext == "pdf":
                src_text = read_pdf_text(io.BytesIO(bio.getvalue()))

        # ========== è·¯å¾„ B:ä¸¤ä¸ªæ–‡ä»¶(åŸæ–‡ + è¯‘æ–‡)==========
        elif two_src is not None and two_tgt is not None:
            def read_any(f):
                e = (f.name.split(".")[-1] or "").lower()
                b = io.BytesIO(f.getvalue())
                if e == "docx":
                    return read_docx_text(b)
                if e == "txt":
                    return read_txt(b)
                if e == "csv":
                    try:
                        df = pd.read_csv(b)
                        return "\n".join(df.iloc[:, 0].astype(str).fillna(""))
                    except Exception:
                        return ""
                if e == "pdf":
                    return read_pdf_text(b)
                return ""
            src_text = read_any(two_src)
            tgt_text = read_any(two_tgt)

        # ========== é¢„è§ˆä¸å†³å®šå…¥åº“æ–¹å¼ ==========
        # æƒ…å†µ 1:æœ‰ pairs(æ¥è‡ª DOCX è¡¨æ ¼)
        if pairs:
            st.success(f"è§£æåˆ° {len(pairs)} å¯¹(DOCX è¡¨æ ¼)")
            preview_df = pd.DataFrame(pairs[:200], columns=["æºå¥", "ç›®æ ‡å¥"])

        # æƒ…å†µ 2:æ²¡æœ‰ pairsï¼Œä½†æ‹¿åˆ°äº† src/tgt æ–‡æœ¬ â†’ åˆ‡å¥/å¯¹é½
        elif src_text and tgt_text:
            sents_src = split_sents(src_text, "zh" if lp.startswith("ä¸­") else "auto")
            sents_tgt = split_sents(tgt_text, "en" if lp.startswith("è‹±") else "auto")
            st.caption(f"å°†å¯¹é½: src={len(sents_src)}  tgt={len(sents_tgt)}")
            if st.button("ğŸ” æ‰§è¡Œè¯­ä¹‰å¯¹é½", key="do_align"):
                pairs_aligned = align_semantic(sents_src, sents_tgt, max_jump=5)
                st.info(f"å¯¹é½å¾—åˆ° {len(pairs_aligned)} å¯¹")
                pairs = [(s, t) for (s, t, score) in pairs_aligned]
                if pairs:
                    preview_df = pd.DataFrame(pairs[:200], columns=["æºå¥", "ç›®æ ‡å¥"])

        # æƒ…å†µ 3:åªæœ‰å•è¯­æ–‡æœ¬(PDF/DOCX/TXT)
        elif src_text and not tgt_text:
            sents_src = split_sents(src_text, "zh" if lp.startswith("ä¸­") else "auto")
            st.info(f"æ£€æµ‹åˆ°å•è¯­æ–‡æœ¬ï¼Œå…± {len(sents_src)} å¥ã€‚å°†ä»¥å•è¯­è¯­æ–™å†™å…¥(è¯‘æ–‡ä¸ºç©º)ã€‚")
            preview_df = pd.DataFrame(
                [{"æºå¥": s, "ç›®æ ‡å¥": ""} for s in sents_src[:200]]
            )

        if preview_df is not None:
            st.dataframe(preview_df, width='stretch')

        # â€”â€” æŒ‰é’® + é€‰é¡¹:å¯¼å…¥è¯­æ–™åº“ | åŒæ—¶é‡å»ºç´¢å¼•
        c_imp, c_opt, c_build = st.columns([1, 1, 1])
        do_import = c_imp.button("ğŸ“¥ å†™å…¥è¯­æ–™åº“", type="primary", key="write_pairs_btn")
        do_build_opt = c_opt.checkbox("å¯¼å…¥åç«‹å³é‡å»ºç´¢å¼•", value=True, key="build_vec_opt")
        only_build_now = c_build.button("ğŸ§  ä»…é‡å»ºç´¢å¼•(ä¸å¯¼å…¥)", key="only_build")

        st.caption("æç¤º: ç´¢å¼•ä¹Ÿå¯ä»¥ç¨ååœ¨â€œä½¿ç”¨ä¸ç´¢å¼• / å¯¼å‡ºâ€é¡µçš„ C åŒºç»Ÿä¸€é‡å»ºã€‚")

        # ===== è¿™é‡Œå¼€å§‹ç”¨ç»Ÿä¸€ç®¡çº¿ =====
        # ç»Ÿä¸€ç®—ä¸€ä¸ªå…œåº•æ ‡é¢˜ï¼ˆä¼˜å…ˆç”¨ç•Œé¢ä¸Šçš„ titleï¼Œå†ç”¨æ–‡ä»¶åï¼‰
        default_title = ""
        if one_file is not None:
            default_title = one_file.name
        elif two_src is not None:
            default_title = two_src.name

        if do_import:
            import_corpus_from_upload(
                st,
                cur,
                conn,
                pid=pid,              # ä½ ä¸Šé¢ meta åŒºçš„é¡¹ç›® ID
                title=title,          # ä½ ä¸Šé¢è¾“å…¥çš„è¯­æ–™æ ‡é¢˜
                lp=lp,                # æ–¹å‘é€‰æ‹©
                pairs=pairs,
                src_text=src_text,
                tgt_text=tgt_text,
                default_title=default_title,
                build_after_import=do_build_opt,
            )

        if only_build_now:
            # ä»…é‡å»ºå½“å‰é¡¹ç›®çš„è¯­ä¹‰ç´¢å¼•(ä¸å¯¼å…¥æ–°è¯­æ–™)
            if pid:
                res_idx = rebuild_project_semantic_index(cur, pid, split_fn=_split_pair_for_index)
                if res_idx.get("ok"):
                    st.success(
                        f"ğŸ§  ç´¢å¼•å·²é‡å»º: æ–°å¢ {res_idx['added']}ï¼Œæ€»é‡ {res_idx['total']}ã€‚"
                    )
                else:
                    st.error(f"é‡å»ºå¤±è´¥: {res_idx.get('msg','æœªçŸ¥é”™è¯¯')}")
            else:
                st.warning("è¯·å…ˆåœ¨ä¸Šæ–¹å¡«å†™æœ‰æ•ˆçš„é¡¹ç›®IDï¼Œå†é‡å»ºç´¢å¼•ã€‚")

    # -------- æµè§ˆ/æ£€ç´¢ --------
    with sub[1]:
        st.subheader("ğŸ” æµè§ˆ/æ£€ç´¢")
        k1, k2, k3 = st.columns([2, 1, 1])
        with k1:
            kw = st.text_input("å…³é”®è¯(æ ‡é¢˜/å¤‡æ³¨/è¯‘æ–‡)", "", key=sk("kw"))
        with k2:
            lp_filter = st.selectbox("æ–¹å‘è¿‡æ»¤", ["å…¨éƒ¨", "ä¸­è¯‘è‹±", "è‹±è¯‘ä¸­", "è‡ªåŠ¨"], key=sk("lp_filter"))
        with k3:
            limit = st.number_input("æ¡æ•°", min_value=10, max_value=1000, value=200, step=10, key=sk("limit"))

        sql = """
        SELECT id, title, IFNULL(project_id,''), IFNULL(lang_pair,''), 
               substr(IFNULL(tgt_text,''),1,80), created_at
        FROM corpus
        WHERE 1=1
        """
        params = []
        if kw.strip():
            like = f"%{kw.strip()}%"
            sql += " AND (title LIKE ? OR IFNULL(note,'') LIKE ? OR IFNULL(tgt_text,'') LIKE ?)"
            params.extend([like, like, like])
        if lp_filter != "å…¨éƒ¨":
            sql += " AND lang_pair=?"
            params.append(lp_filter)
        sql += " ORDER BY id DESC LIMIT ?"
        params.append(int(limit))

        rows = cur.execute(sql, params).fetchall()
        if not rows:
            st.info("æš‚æ— åŒ¹é…è¯­æ–™ã€‚")

        else:
            for rid, ttl, pj, lpv, prev, ctime in rows:
                with st.expander(f"[{rid}] {ttl} | é¡¹ç›®:{pj} | æ–¹å‘:{lpv} | {ctime}"):
                    st.write(f"**ID**: {rid}  **é¡¹ç›®ID**: {pj}  **æ–¹å‘**: {lpv}  **æ—¶é—´**: {ctime}")
                    st.write(f"**é¢„è§ˆ(è¯‘æ–‡å‰80å­—)**: {prev}")
                    det = cur.execute(
                        "SELECT IFNULL(src_text,''), IFNULL(tgt_text,'') FROM corpus WHERE id=?",
                        (rid,)
                    ).fetchone()
                    src_all, tgt_all = det or ("", "")
                    st.text_area("æºæ–‡", src_all, height=160, key=sk(f"src_{rid}"))
                    st.text_area("è¯‘æ–‡", tgt_all, height=160, key=sk(f"tgt_{rid}"))

                    c1, c2, c3, c4 = st.columns(4)
                    with c1:
                        if st.button("åŠ å…¥å‚è€ƒé›†åˆ", key=sk(f"add_ref_{rid}")):
                            target_pid = st.session_state.get("corpus_target_project")
                            if not target_pid:
                                st.warning("è¯·å…ˆåœ¨ä¸Šæ–¹é€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®ï¼Œå†æ·»åŠ å‚è€ƒè¯­æ–™ã€‚")
                            else:
                                refs = get_project_ref_ids(target_pid)
                                refs.add(int(rid))
                                st.success(f"âœ… å·²åŠ å…¥é¡¹ç›® #{target_pid} çš„å‚è€ƒé›†åˆ(â€œä½¿ç”¨ä¸å¯¼å‡ºâ€æŸ¥çœ‹)")
                    with c2:
                        if st.button("å¯¼å‡ºTXT", key=sk(f"cor_txt_{rid}")):
                            st.download_button(
                                "ä¸‹è½½è¯‘æ–‡TXT",
                                tgt_all or "",
                                file_name=f"corpus_{rid}.txt",
                                mime="text/plain",
                                key=sk(f"cor_txt_dl_{rid}")
                            )
                    with c3:
                        if st.button("å¯¼å‡ºCSV(ä¸­è‹±å¯¹ç…§)", key=sk(f"cor_csv_{rid}")):
                            df_out = pd.DataFrame(
                                [{"source": src_all, "target": tgt_all}]
                            )
                            csv_data = df_out.to_csv(index=False)
                            st.download_button(
                                "ä¸‹è½½CSV",
                                csv_data,
                                file_name=f"corpus_{rid}.csv",
                                mime="text/csv",
                                key=sk(f"cor_csv_dl_{rid}")
                            )
                    with c4:
                        if st.button("åˆ é™¤", key=sk(f"del_{rid}")):
                            cur.execute("DELETE FROM corpus WHERE id=?", (rid,))
                            conn.commit()
                            st.warning("ğŸ—‘ï¸ å·²åˆ é™¤ï¼Œåˆ·æ–°åç”Ÿæ•ˆ")
                            st.rerun()

    # -------- ä½¿ç”¨ä¸å¯¼å‡º --------
    with sub[2]:
        st.subheader("ğŸ§© ä½¿ç”¨ä¸ç´¢å¼• / å¯¼å‡º")

        proj_rows = cur.execute("SELECT id, IFNULL(title,'(æœªå‘½å)') FROM items WHERE COALESCE(type,'')='project' ORDER BY id DESC LIMIT 200").fetchall()
        proj_options = {"(è¯·é€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®)": None}
        proj_options.update({f"[{pid}] {ttl}": pid for pid, ttl in proj_rows})
        option_labels = list(proj_options.keys())
        saved_label = st.session_state.get("corpus_target_label")
        if saved_label not in option_labels:
            saved_label = option_labels[0]
        selection_label = st.selectbox(
            "Few-shot å‚è€ƒé›†åˆå°†ç»‘å®šåˆ°å“ªä¸ªé¡¹ç›®ï¼Ÿ",
            option_labels,
            index=option_labels.index(saved_label),
            key="corpus_proj_select",
        )
        st.session_state["corpus_target_label"] = selection_label
        st.session_state["corpus_target_project"] = proj_options.get(selection_label)
        if st.session_state["corpus_target_project"]:
            st.caption(f"å½“å‰ Few-shot ç›®æ ‡: {selection_label}")
        else:
            st.caption("æœªé€‰æ‹©é¡¹ç›®:è¯·å…ˆåœ¨æ­¤æŒ‡å®šç›®æ ‡é¡¹ç›®ï¼Œå†å»å…¶ä»–å­é¡µæ·»åŠ å‚è€ƒç¤ºä¾‹ã€‚")

        # A åŒº:å‚è€ƒé›†åˆåˆå¹¶ä¸å¯¼å‡º
        target_pid = st.session_state.get("corpus_target_project")
        if not target_pid:
            st.info("è¯·å…ˆé€šè¿‡é¡µé¢ä¸Šæ–¹çš„ä¸‹æ‹‰æ¡†é€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®ï¼Œå†ç®¡ç†å‚è€ƒé›†åˆã€‚")
        else:
            ids = sorted({int(x) for x in get_project_ref_ids(target_pid)}, reverse=True)
            st.caption(f"é¡¹ç›® #{target_pid} çš„å·²é€‰å‚è€ƒæ•°: {len(ids)}")
            if ids:
                qmarks = ",".join(["?"] * len(ids))
                dets = cur.execute(
                    f"SELECT id, title, lang_pair, IFNULL(src_text,''), IFNULL(tgt_text,'') "
                    f"FROM corpus WHERE id IN ({qmarks})",
                    ids
                ).fetchall()
                order_map = {rid: idx for idx, rid in enumerate(ids)}
                dets.sort(key=lambda row: order_map.get(row[0], len(order_map)))
                merged_demo = "\n\n---\n\n".join(
                    [f"\n\næºæ–‡:\n{src}\n\nè¯‘æ–‡:\n{tgt}" for (_, _, _, src, tgt) in dets]
                )
                st.text_area("åˆå¹¶é¢„è§ˆ", merged_demo, height=240, key=sk("merge_preview"))

                cxa, cxb = st.columns(2)
                with cxa:
                    if st.button("æ¸…ç©ºå‚è€ƒé›†åˆ", key=sk(f"clear_refs_{target_pid}")):
                        refs = get_project_ref_ids(target_pid)
                        refs.clear()
                        st.info(f"å·²æ¸…ç©ºé¡¹ç›® #{target_pid} çš„å‚è€ƒé›†åˆ")
                with cxb:
                    if st.button("å¯¼å‡ºå‚è€ƒTXT", key=sk(f"export_refs_txt_{target_pid}")):
                        st.download_button(
                            "ä¸‹è½½TXT",
                            merged_demo,
                            file_name=f"corpus_refs_{target_pid}.txt",
                            mime="text/plain",
                            key=sk(f"export_refs_txt_dl_{target_pid}")
                        )
            else:
                st.info("è¿˜æ²¡æœ‰é€‰æ‹©ä»»ä½•å‚è€ƒè¯­æ–™ï¼Œå¯ä»¥åœ¨â€œæµè§ˆ/æ£€ç´¢â€ä¸­å‹¾é€‰åå†æ¥ã€‚")

        st.markdown("---")

        # B åŒº:Few-shot æ³¨å…¥å¼€å…³
        if not target_pid:
            st.info("é€‰æ‹©ç›®æ ‡é¡¹ç›®åæ‰èƒ½é…ç½® Few-shot æ³¨å…¥å¼€å…³ã€‚")
            use_fs = False
        else:
            curr_state = get_project_fewshot_enabled(target_pid)
            use_fs = st.checkbox(
                "ç¿»è¯‘æ—¶è‡ªåŠ¨æ³¨å…¥è¿™äº›å‚è€ƒè¯­æ–™ä½œä¸º Few-shot æç¤º",
                value=curr_state,
                key=sk(f"use_fs_{target_pid}")
            )
        if st.button("ä¿å­˜å‚è€ƒæ³¨å…¥å¼€å…³", key=sk("save_fs")):
            if not target_pid:
                st.warning("è¯·å…ˆé€‰æ‹© Few-shot ç›®æ ‡é¡¹ç›®")
            else:
                set_project_fewshot_enabled(target_pid, use_fs)
                st.success(
                    f"å·²æ›´æ–°:é¡¹ç›® #{target_pid} "
                    + ("å°†æ³¨å…¥å‚è€ƒ few-shot" if use_fs else "ä¸ä¼šè‡ªåŠ¨æ³¨å…¥å‚è€ƒ")
                )

        st.markdown("---")

        # C åŒº:é¡¹ç›®çº§ç´¢å¼•ç®¡ç† + è¯­ä¹‰å¬å›æµ‹è¯•
        st.subheader("ğŸ§  è¯­ä¹‰ç´¢å¼•ç®¡ç† & å¬å›æµ‹è¯•")

        # é€‰æ‹©é¡¹ç›®
        proj_rows = cur.execute(
            """
            SELECT id, title
            FROM items
            WHERE COALESCE(type,'')='project'
            ORDER BY id DESC
            LIMIT 200
            """
        ).fetchall()
        proj_map = {"(è¯·é€‰æ‹©)": None}
        proj_map.update({f"[{i}] {t}": i for (i, t) in proj_rows})
        proj_sel = st.selectbox("é€‰æ‹©è¦æµ‹è¯•/é‡å»ºç´¢å¼•çš„é¡¹ç›®", list(proj_map.keys()), key=sk("vec_proj"))
        pid_sel = proj_map.get(proj_sel)
        # æ˜¾ç¤ºå½“å‰é¡¹ç›®ç´¢å¼•ä¸­ corpus / history ç»Ÿè®¡
        idx_total = idx_corpus = idx_hist = idx_other = 0
        if pid_sel:
            try:
                mode, index_obj, mapping, vecs = _load_index(int(pid_sel))
                if isinstance(mapping, list):
                    idx_total = len(mapping)
                    for m in mapping:
                        src_tag = (m.get("source") or "").lower()
                        if src_tag == "history":
                            idx_hist += 1
                        elif src_tag in ("", "corpus"):
                            idx_corpus += 1
                        else:
                            idx_other += 1
            except Exception:
                # ç´¢å¼•æ–‡ä»¶æŸå/ä¸å­˜åœ¨æ—¶ç›´æ¥å¿½ç•¥ç»Ÿè®¡
                pass

        if pid_sel:
            st.caption(
                f"å½“å‰ç´¢å¼•æ¡æ•°: {idx_total} æ¡ "
                f"(è¯­æ–™åº“: {idx_corpus} æ¡, æ¥è‡ªç¿»è¯‘å†å²: {idx_hist} æ¡, å…¶ä»–: {idx_other} æ¡)ã€‚"
            )
        else:
            st.caption("è¯·é€‰æ‹©é¡¹ç›®ä»¥æŸ¥çœ‹è¯¥é¡¹ç›®çš„ç´¢å¼•çŠ¶æ€ã€‚")


        c_build1, c_build2 = st.columns(2)
        with c_build1:
            if st.button("æ„å»º/æ›´æ–°è¯¥é¡¹ç›®ç´¢å¼•", key=sk("build_idx_btn")):
                if pid_sel:
                    res_idx = rebuild_project_semantic_index(cur, pid_sel, split_fn=_split_pair_for_index)
                    if res_idx.get("ok"):
                        st.success(
                            f"ç´¢å¼•å·²æ›´æ–°: æ–°å¢ {res_idx['added']}ï¼Œæ€»é‡ {res_idx['total']}ã€‚"
                        )
                    else:
                        st.error(f"æ„å»ºå¤±è´¥: {res_idx.get('msg','æœªçŸ¥é”™è¯¯')}")
                else:
                    st.warning("è¯·å…ˆé€‰æ‹©å…·ä½“é¡¹ç›®ã€‚")

        with c_build2:
            st.caption("è¯´æ˜:ç´¢å¼•ç”¨äºè¯­ä¹‰å¬å›å‚è€ƒä¾‹å¥ï¼Œç¿»è¯‘æ—¶ç”±ç³»ç»Ÿè‡ªåŠ¨è°ƒç”¨ã€‚")

        q_demo = st.text_area("è¯•æœä¸€å¥è¯(å°†ä»¥è¯­ä¹‰ç›¸ä¼¼æ£€ç´¢å‚è€ƒ)", "", height=80, key=sk("q_demo"))
        topk = st.number_input("Top-K", 1, 10, 5, key=sk("q_topk"))
        if st.button("ğŸ” è¯­ä¹‰å¬å›æµ‹è¯•", key=sk("q_vec")):
            if pid_sel and q_demo.strip():
                hits = semantic_retrieve(pid_sel, q_demo.strip(), topk=int(topk), cur=cur)
                if not hits:
                    st.info("ç´¢å¼•ä¸ºç©ºæˆ–æœªå‘½ä¸­ã€‚è¯·å…ˆæ„å»ºç´¢å¼•æˆ–å¢åŠ è¯­æ–™ã€‚")
                else:
                    for row in hits:
                        sc, m, txt = row[:3]   # åªæ‹¿å‰ 3 ä¸ªï¼Œåé¢å¤šä½™çš„å¿½ç•¥
                        st.write(f"**{sc:.3f}** | {m.get('title','')} | {m.get('lang_pair','')}")
                        st.code(txt, language="text")
                        st.markdown("---")
            else:
                st.warning("è¯·å…ˆé€‰æ‹©é¡¹ç›®å¹¶è¾“å…¥è¦æ£€ç´¢çš„å†…å®¹ã€‚")

elif choice.startswith("ğŸ§ "):
    render_index_manager_by_domain(st, conn, cur)

